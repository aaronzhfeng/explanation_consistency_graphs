---
source: https://arxiv.org/abs/2405.19902
html: https://arxiv.org/html/2405.19902
title: "Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"
---

  1. [1 Introduction](https://arxiv.org/html/2405.19902v1#S1 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  2. [2 Related Work](https://arxiv.org/html/2405.19902v1#S2 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  3. [3 Problem Formulation](https://arxiv.org/html/2405.19902v1#S3 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  4. [4 Methodology](https://arxiv.org/html/2405.19902v1#S4 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     1. [4.1 Overview](https://arxiv.org/html/2405.19902v1#S4.SS1 "In 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     2. [4.2 Corrupted dataset construction](https://arxiv.org/html/2405.19902v1#S4.SS2 "In 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     3. [4.3 Training dynamics generation](https://arxiv.org/html/2405.19902v1#S4.SS3 "In 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
        1. [4.3.1 Training dynamics](https://arxiv.org/html/2405.19902v1#S4.SS3.SSS1 "In 4.3 Training dynamics generation â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
        2. [4.3.2 Dynamics generation for noisy label detection](https://arxiv.org/html/2405.19902v1#S4.SS3.SSS2 "In 4.3 Training dynamics generation â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     4. [4.4 Noisy label detection via dynamics clustering](https://arxiv.org/html/2405.19902v1#S4.SS4 "In 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
        1. [4.4.1 Identification of incorrectly labeled instances](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS1 "In 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
        2. [4.4.2 Learning discriminative patterns in dynamics](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS2 "In 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
        3. [4.4.3 Validation metric](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS3 "In 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  5. [5 Experiments](https://arxiv.org/html/2405.19902v1#S5 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     1. [5.1 Experiment setup](https://arxiv.org/html/2405.19902v1#S5.SS1 "In 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     2. [5.2 Noisy label detection performance](https://arxiv.org/html/2405.19902v1#S5.SS2 "In 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     3. [5.3 Effectiveness of validation metric](https://arxiv.org/html/2405.19902v1#S5.SS3 "In 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     4. [5.4 Quantitative analyses](https://arxiv.org/html/2405.19902v1#S5.SS4 "In 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     5. [5.5 Compatibility analyses with robust learning](https://arxiv.org/html/2405.19902v1#S5.SS5 "In 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  6. [6 Conclusion](https://arxiv.org/html/2405.19902v1#S6 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  7. [7 Acknowledgements](https://arxiv.org/html/2405.19902v1#S7 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  8. [A Experiment Setup](https://arxiv.org/html/2405.19902v1#A1 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     1. [A.1 Datasets](https://arxiv.org/html/2405.19902v1#A1.SS1 "In Appendix A Experiment Setup â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     2. [A.2 Reproducibility](https://arxiv.org/html/2405.19902v1#A1.SS2 "In Appendix A Experiment Setup â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  9. [B Analyses of Training Dynamics](https://arxiv.org/html/2405.19902v1#A2 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     1. [B.1 Preliminaries](https://arxiv.org/html/2405.19902v1#A2.SS1 "In Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     2. [B.2 Temporal patterns in training dynamics](https://arxiv.org/html/2405.19902v1#A2.SS2 "In Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
     3. [B.3 Comparison of various training signals](https://arxiv.org/html/2405.19902v1#A2.SS3 "In Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  10. [C Proof of the Lower Bound of Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT](https://arxiv.org/html/2405.19902v1#A3 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")
  11. [D Compatibility analysis with robust learning on Clothing 1M dataset](https://arxiv.org/html/2405.19902v1#A4 "In Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")



# Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection

Suyeon Kim1, Dongha Lee2, SeongKu Kang3, Sukang Chae1, Sanghwan Jang1, Hwanjo Yu111footnotemark: 1   
1 POSTECH, 2 Yonsei University, 3 University of Illinois at Urbana Champaign   
{kimsu, chaesgng2, s.jang, hwanjoyu}@postech.ac.kr, donalee@yonsei.ac.kr, seongku@illinois.edu  Corresponding authors

###### Abstract

Label noise, commonly found in real-world datasets, has a detrimental impact on a modelâ€™s generalization. To effectively detect incorrectly labeled instances, previous works have mostly relied on distinguishable training signals, such as training loss, as indicators to differentiate between clean and noisy labels. However, they have limitations in that the training signals incompletely reveal the modelâ€™s behavior and are not effectively generalized to various noise types, resulting in limited detection accuracy. In this paper, we propose DynaCor framework that distinguishes incorrectly labeled instances from correctly labeled ones based on the dynamics of the training signals. To cope with the absence of supervision for clean and noisy labels, DynaCor first introduces a label corruption strategy that augments the original dataset with intentionally corrupted labels, enabling indirect simulation of the modelâ€™s behavior on noisy labels. Then, DynaCor learns to identify clean and noisy instances by inducing two clearly distinguishable clusters from the latent representations of training dynamics. Our comprehensive experiments show that DynaCor outperforms the state-of-the-art competitors and shows strong robustness to various noise types and noise rates.

##  1 Introduction

The remarkable success of deep neural networks (DNNs) is largely attributed to massive and accurately labeled datasets. However, creating such datasets is not only expensive but also time-consuming. As a cost-effective alternative, various methods have been employed for label collection, such as crowdsourcing [[11](https://arxiv.org/html/2405.19902v1#bib.bib11)] and extracting image labels from accompanying text on the web [[57](https://arxiv.org/html/2405.19902v1#bib.bib57), [29](https://arxiv.org/html/2405.19902v1#bib.bib29)]. Unfortunately, these approaches have led to the emergence of noise in real-world datasets, with reported noise rates ranging from 8.0% to 38.5% [[57](https://arxiv.org/html/2405.19902v1#bib.bib57), [29](https://arxiv.org/html/2405.19902v1#bib.bib29), [27](https://arxiv.org/html/2405.19902v1#bib.bib27)], which severely degrades the modelâ€™s performance [[62](https://arxiv.org/html/2405.19902v1#bib.bib62), [1](https://arxiv.org/html/2405.19902v1#bib.bib1)].

To cope with the detrimental effect of such noisy labels, a variety of approaches have been proposed, including noise robust learning that minimizes the impact of inaccurate information from noisy labels during the training process [[31](https://arxiv.org/html/2405.19902v1#bib.bib31), [52](https://arxiv.org/html/2405.19902v1#bib.bib52), [57](https://arxiv.org/html/2405.19902v1#bib.bib57), [7](https://arxiv.org/html/2405.19902v1#bib.bib7)] and data re-annotation through algorithmic methods [[41](https://arxiv.org/html/2405.19902v1#bib.bib41), [16](https://arxiv.org/html/2405.19902v1#bib.bib16), [65](https://arxiv.org/html/2405.19902v1#bib.bib65)]. Among them, the task of noisy label detection, which our work mainly focuses on, aims to identify incorrectly labeled instances in a training dataset [[7](https://arxiv.org/html/2405.19902v1#bib.bib7), [36](https://arxiv.org/html/2405.19902v1#bib.bib36), [22](https://arxiv.org/html/2405.19902v1#bib.bib22)]. This task has gained much attention in that it can be further utilized for improving the quality of the original dataset via cleansing or rectifying such instances.

Motivated by the memorization effect, which refers to the phenomenon where DNNs initially grasp simple and generalized patterns in correctly labeled data and then gradually overfit to incorrectly labeled data [[1](https://arxiv.org/html/2405.19902v1#bib.bib1)], most existing studies have utilized distinguishable training signals as indicators of label quality to differentiate between clean and noisy labels. To elaborate, these training signals are derived from the modelâ€™s behavior on individual instances during the training [[44](https://arxiv.org/html/2405.19902v1#bib.bib44), [47](https://arxiv.org/html/2405.19902v1#bib.bib47)], involving factors such as training loss or confidence scores. Note that it is impractical to acquire annotations explicitly indicating whether each instance is correctly labeled or not. Hence, numerous studies have crafted various heuristic training signals [[12](https://arxiv.org/html/2405.19902v1#bib.bib12), [19](https://arxiv.org/html/2405.19902v1#bib.bib19), [22](https://arxiv.org/html/2405.19902v1#bib.bib22)], designed based on human prior knowledge of the modelâ€™s distinctive behaviors when faced with clean and noisy labels.

Despite their effectiveness, the training signal-based detection methods still exhibit several limitations: (1) They only focus on a scalar signal at a single epoch (or a representative one across the entire training trajectory), which leads to limited detection accuracy (See Appendix B.2). Since the modelâ€™s distinct behaviors on clean and noisy labels draw different temporal trajectories of training signals, a single scalar is insufficient to distinguish them by capturing temporal patterns within training dynamics. (2) Existing detection approaches based on heuristics are not effectively generalized to various types of label noise. Noisy labels can originate from diverse sources, including human annotator errors [[35](https://arxiv.org/html/2405.19902v1#bib.bib35), [53](https://arxiv.org/html/2405.19902v1#bib.bib53)], systematic biases [[49](https://arxiv.org/html/2405.19902v1#bib.bib49)], and unreliable annotations from web crawling [[57](https://arxiv.org/html/2405.19902v1#bib.bib57)], resulting in different noise types and rates for each dataset; this eventually requires considerable efforts to tune hyperparameters for training recipes of DNNs [[28](https://arxiv.org/html/2405.19902v1#bib.bib28), [31](https://arxiv.org/html/2405.19902v1#bib.bib31), [48](https://arxiv.org/html/2405.19902v1#bib.bib48)].

To tackle these challenges, our goal is to propose a fully data-driven approach that directly learns to distinguish the training dynamics of noisy labels from those of clean labels using a given dataset without solely relying on heuristics. The primary technical challenge in this data-driven approach arises from the absence of supervision for clean and noisy labels. As a solution, we introduce a label corruption strategyâ€“image augmentation attaching intentionally corrupted labels via random label replacement. Since the augmented instances are highly likely to have incorrect labels, we can utilize them to capture the training dynamics of noisy labels. In other words, this allows us to simulate the modelâ€™s behavior on noisy labels by leveraging the augmented instances with corrupted labels.

In this work, we present a novel framework, named DynaCor, that learns discriminative Dynamics with label Corruption for noisy label detection. To be specific, DynaCor identifies clean and noisy labels via clustering of latent representations of training dynamics. To this end, it first generates training dynamics of original instances and corrupted instances. Then, it computes the dynamics representations that encode discriminative patterns within the training trajectories by using a parametric dynamics encoder. The dynamics encoder is optimized to induce two clearly distinguishable clusters (i.e., each for clean and noisy instances) based on two different types of losses for (1) high cluster cohesion and (2) cluster alignment between original and corrupted instances. Furthermore, DynaCor adopts a simple validation metric for the dynamics encoder based on the clustering quality so as to indirectly estimate its detection performance where ground-truth annotations of clean and noisy labels are not available for validation as well.

The contribution of this work is threefold as follows:

  * â€¢

We introduce a label corruption strategy that augments the original data with corrupted labels, which are highly likely to be noisy, enabling indirect simulation of the modelâ€™s behavior on noisy labels during the training.

  * â€¢

We present a data-driven DynaCor framework to distinguish incorrectly labeled instances from correctly labeled ones via clustering of the training dynamics.

  * â€¢

Our extensive experiments on real-world datasets demonstrate that DynaCor achieves the highest accuracy in detecting incorrectly labeled instances and remarkable robustness to various noise types and noise rates.




##  2 Related Work

Figure 1: The proposed DynaCor framework consists of three steps: (1) Corrupted dataset construction generates the augmented images with corrupted labels, likely resulting in noisy labels, in order to provide guidance for discrimination between clean and noisy labels. (2) Training dynamics generation collects the trajectory of training signals for both the original and corrupted datasets by training a classifier. (3) Noisy label detection is performed by discovering two distinguishable clusters of dynamics representations, and for this, the dynamics encoder is optimized to enhance both cluster cohesion and alignment between the original and the corrupted datasets.

We provide a brief overview of the two primary research directions for addressing incorrectly labeled instances in a noisy dataset: (1) Noisy label detection focuses on identifying instances that are incorrectly labeled within a dataset, aiming to enhance data quality. (2) Noise robust learning is centered on developing learning algorithms and models that are resilient to the impact of noisy labels, ensuring robust performance even in the presence of labeling errors.

Noisy label detection.  The main challenge in detecting noisy labels lies in defining a surrogate metric for label quality, essentially indicating how likely an instance is correctly labeled. The widely adopted option is the training loss, assessing the disparity between the model prediction and given labels [[20](https://arxiv.org/html/2405.19902v1#bib.bib20), [15](https://arxiv.org/html/2405.19902v1#bib.bib15), [19](https://arxiv.org/html/2405.19902v1#bib.bib19)], with higher loss often indicating incorrect labels. Various proxy measures, including gradient-based values [[64](https://arxiv.org/html/2405.19902v1#bib.bib64), [50](https://arxiv.org/html/2405.19902v1#bib.bib50)] and prediction-based metrics [[33](https://arxiv.org/html/2405.19902v1#bib.bib33), [43](https://arxiv.org/html/2405.19902v1#bib.bib43), [41](https://arxiv.org/html/2405.19902v1#bib.bib41), [36](https://arxiv.org/html/2405.19902v1#bib.bib36)] have been developed to differentiate between clean and noisy labels, utilizing methods like Gaussian mixture models [[68](https://arxiv.org/html/2405.19902v1#bib.bib68), [28](https://arxiv.org/html/2405.19902v1#bib.bib28), [22](https://arxiv.org/html/2405.19902v1#bib.bib22), [4](https://arxiv.org/html/2405.19902v1#bib.bib4)] or manually designed thresholds [[33](https://arxiv.org/html/2405.19902v1#bib.bib33), [15](https://arxiv.org/html/2405.19902v1#bib.bib15), [60](https://arxiv.org/html/2405.19902v1#bib.bib60), [67](https://arxiv.org/html/2405.19902v1#bib.bib67), [36](https://arxiv.org/html/2405.19902v1#bib.bib36)]. However, these approaches may overlook the potential benefits of adopting a data-driven (or learning-centric) detection model [[7](https://arxiv.org/html/2405.19902v1#bib.bib7)], which can be easily generalized to various noise types and levels. As a training-free alternative, a recent study [[67](https://arxiv.org/html/2405.19902v1#bib.bib67)] introduces a non-parametric KNN-based approach based on the assumption that instances situated closely in the input feature spaces derived from a pre-trained model are more likely to share the same clean label. However, its efficacy in detection heavily depends on the quality of the pre-trained model and may not be universally applicable across domains with specific fine-grained visual features.

Noise robust learning.  Extensive research have focused on creating noise robust methods: loss functions [[64](https://arxiv.org/html/2405.19902v1#bib.bib64), [50](https://arxiv.org/html/2405.19902v1#bib.bib50)], regularization [[31](https://arxiv.org/html/2405.19902v1#bib.bib31), [8](https://arxiv.org/html/2405.19902v1#bib.bib8), [6](https://arxiv.org/html/2405.19902v1#bib.bib6)], model architectures [[57](https://arxiv.org/html/2405.19902v1#bib.bib57), [5](https://arxiv.org/html/2405.19902v1#bib.bib5), [2](https://arxiv.org/html/2405.19902v1#bib.bib2), [21](https://arxiv.org/html/2405.19902v1#bib.bib21), [13](https://arxiv.org/html/2405.19902v1#bib.bib13), [59](https://arxiv.org/html/2405.19902v1#bib.bib59), [9](https://arxiv.org/html/2405.19902v1#bib.bib9)], and training strategies [[63](https://arxiv.org/html/2405.19902v1#bib.bib63), [55](https://arxiv.org/html/2405.19902v1#bib.bib55), [32](https://arxiv.org/html/2405.19902v1#bib.bib32), [23](https://arxiv.org/html/2405.19902v1#bib.bib23)]. Recent studies have endeavored to integrate the process of detecting noisy labels and appropriately addressing them into the training pipeline in various ways: re-weighting losses [[20](https://arxiv.org/html/2405.19902v1#bib.bib20), [38](https://arxiv.org/html/2405.19902v1#bib.bib38), [40](https://arxiv.org/html/2405.19902v1#bib.bib40)] or re-annotation [[41](https://arxiv.org/html/2405.19902v1#bib.bib41), [16](https://arxiv.org/html/2405.19902v1#bib.bib16), [65](https://arxiv.org/html/2405.19902v1#bib.bib65)]. Besides, several studies [[28](https://arxiv.org/html/2405.19902v1#bib.bib28), [48](https://arxiv.org/html/2405.19902v1#bib.bib48), [54](https://arxiv.org/html/2405.19902v1#bib.bib54), [4](https://arxiv.org/html/2405.19902v1#bib.bib4)] treat detected noisy labels as unlabeled and make use of established semi-supervised techniques [[16](https://arxiv.org/html/2405.19902v1#bib.bib16), [65](https://arxiv.org/html/2405.19902v1#bib.bib65), [63](https://arxiv.org/html/2405.19902v1#bib.bib63), [3](https://arxiv.org/html/2405.19902v1#bib.bib3)]. Current robust learning typically relies on clean data, i.e., test data, for validation, while noisy detection methods can function without it, making direct comparisons difficult [[67](https://arxiv.org/html/2405.19902v1#bib.bib67)]. In this sense, we will discuss how these noise robust learning approaches can be effectively combined with noisy detection methods (Sec. [5.5](https://arxiv.org/html/2405.19902v1#S5.SS5 "5.5 Compatibility analyses with robust learning â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")).

##  3 Problem Formulation

For multi-class classification, let ğ’³ğ’³\mathcal{X}caligraphic_X be an input feature space and ğ’´={1,2,..,C}\mathcal{Y}=\\{1,2,..,C\\}caligraphic_Y = { 1 , 2 , . . , italic_C } be a label space. Consider a dataset D={(ğ±n,yn)}n=1Nğ·subscriptsuperscriptsubscriptğ±ğ‘›subscriptğ‘¦ğ‘›ğ‘ğ‘›1D=\\{(\mathbf{x}_{n},y_{n})\\}^{N}_{n=1}italic_D = { ( bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) } start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT, where each sample is independently drawn from an unknown joint distribution over ğ’³Ã—ğ’´ğ’³ğ’´\mathcal{X}\times\mathcal{Y}caligraphic_X Ã— caligraphic_Y. In real-world scenarios, we can only access a noisily labeled training set D~={(ğ±n,y~n)}n=1N~ğ·subscriptsuperscriptsubscriptğ±ğ‘›subscript~ğ‘¦ğ‘›ğ‘ğ‘›1\widetilde{D}=\\{(\mathbf{x}_{n},\tilde{y}_{n})\\}^{N}_{n=1}over~ start_ARG italic_D end_ARG = { ( bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) } start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT, where y~~ğ‘¦\tilde{y}over~ start_ARG italic_y end_ARG denotes a noisy annotation, and there may exist nâˆˆ{1,â€¦,N}ğ‘›1â€¦ğ‘n\in\\{1,...,N\\}italic_n âˆˆ { 1 , â€¦ , italic_N } such that ynâ‰ y~nsubscriptğ‘¦ğ‘›subscript~ğ‘¦ğ‘›y_{n}\neq\tilde{y}_{n}italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT â‰  over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. In this work, we focus on the task of noisy label detection, which aims to identify the incorrectly labeled instances, i.e., {(ğ±n,y~n)âˆˆD~âˆ£ynâ‰ y~n}conditional-setsubscriptğ±ğ‘›subscript~ğ‘¦ğ‘›~ğ·subscriptğ‘¦ğ‘›subscript~ğ‘¦ğ‘›\\{(\mathbf{x}_{n},\tilde{y}_{n})\in\widetilde{D}\mid y_{n}\neq\tilde{y}_{n}\\}{ ( bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) âˆˆ over~ start_ARG italic_D end_ARG âˆ£ italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT â‰  over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }. As an evaluation metric, we use F1 score [[30](https://arxiv.org/html/2405.19902v1#bib.bib30)], treating the incorrectly labeled instances as positive and the remainings as negative.

##  4 Methodology

###  4.1 Overview

DynaCor (Dynamics learning with label Corruption for noisy label detection) framework learns discriminative patterns inherent in training dynamics, thereby distinguishing incorrectly labeled instances from clean ones. As illustrated in Figure [1](https://arxiv.org/html/2405.19902v1#S2.F1 "Figure 1 â€£ 2 Related Work â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"), DynaCor consists of three major steps.

  * â€¢

Corrupted dataset construction (Sec. [4.2](https://arxiv.org/html/2405.19902v1#S4.SS2 "4.2 Corrupted dataset construction â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")): To address the challenge arising from the lack of supervision for incorrectly labeled instances, we introduce a corrupted dataset that intentionally corrupts labels, providing guidance to identify incorrectly labeled instances.

  * â€¢

Training dynamics generation (Sec. [4.3](https://arxiv.org/html/2405.19902v1#S4.SS3 "4.3 Training dynamics generation â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")): We generate training dynamics, which denote a modelâ€™s behavior on individual instances during training, by training a classifier using both the original and the corrupted dataset.

  * â€¢

Noisy label detection via dynamics clustering (Sec. [4.4](https://arxiv.org/html/2405.19902v1#S4.SS4 "4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")): We seek to discover underlying patterns in the training dynamics by learning representations that reflect the intrinsic similarities among data points, leveraging the characteristics of the corrupted dataset. For this, we encode the training dynamics via a dynamics encoder that learns discriminative representation using clustering and alignment losses. Then we find clusters using a robust validation metric designed for dynamics-based clustering.




###  4.2 Corrupted dataset construction

Given the original dataset D~~ğ·\widetilde{D}over~ start_ARG italic_D end_ARG, we construct a corrupted dataset DÂ¯Â¯ğ·\bar{D}overÂ¯ start_ARG italic_D end_ARG by intentionally corrupting labels for a randomly sampled subset of D~~ğ·\widetilde{D}over~ start_ARG italic_D end_ARG with a corruption rate Î³âˆˆ(0,1]ğ›¾01\gamma\in(0,1]italic_Î³ âˆˆ ( 0 , 1 ]. Specifically, to obtain a corrupted instance (ğ±Â¯,yÂ¯)Â¯ğ±Â¯ğ‘¦(\bar{\mathbf{x}},\bar{y})( overÂ¯ start_ARG bold_x end_ARG , overÂ¯ start_ARG italic_y end_ARG ) from an original data instance (ğ±,y~)ğ±~ğ‘¦(\mathbf{x},\tilde{y})( bold_x , over~ start_ARG italic_y end_ARG ), we transform an input image using weak augmentation such as horizontal flip or center crop, i.e., ğ±Â¯=Augâ¢(ğ±)Â¯ğ±Augğ±\bar{\mathbf{x}}=\mathrm{Aug}(\mathbf{x})overÂ¯ start_ARG bold_x end_ARG = roman_Aug ( bold_x ). Then, we randomly flip the class label to one of the other classes, i.e., yÂ¯âˆˆ{1,â€¦,C}\{y~}Â¯ğ‘¦\1â€¦ğ¶~ğ‘¦\bar{y}\in\\{1,...,C\\}\backslash\\{\tilde{y}\\}overÂ¯ start_ARG italic_y end_ARG âˆˆ { 1 , â€¦ , italic_C } \ { over~ start_ARG italic_y end_ARG }. The corrupted dataset, guaranteed to exhibit symmetric noise at a higher rate than the original, provides additional signals for discerning incorrectly labeled instances in the clustering process, as detailed in the following analysis.

Analysis: the noise rate of the corrupted dataset.  We analyze the lower bound on the noise rate of the corrupted dataset DÂ¯Â¯ğ·\bar{D}overÂ¯ start_ARG italic_D end_ARG. Let Î·âˆˆ[0,1]ğœ‚01\eta\in[0,1]italic_Î· âˆˆ [ 0 , 1 ] denote the noise rate of the original dataset D~~ğ·\widetilde{D}over~ start_ARG italic_D end_ARG.111Î·=1|D~|â¢|{(ğ±,y~)âˆˆD~âˆ£y~â‰ y,(ğ±,y)âˆˆD}|ğœ‚1~ğ·conditional-setğ±~ğ‘¦~ğ·formulae-sequence~ğ‘¦ğ‘¦ğ±ğ‘¦ğ·\eta=\frac{1}{|\widetilde{D}|}{|\\{(\mathbf{x},\tilde{y})\in\widetilde{D}\mid% \tilde{y}\neq y,\ (\mathbf{x},y)\in D\\}|}italic_Î· = divide start_ARG 1 end_ARG start_ARG | over~ start_ARG italic_D end_ARG | end_ARG | { ( bold_x , over~ start_ARG italic_y end_ARG ) âˆˆ over~ start_ARG italic_D end_ARG âˆ£ over~ start_ARG italic_y end_ARG â‰  italic_y , ( bold_x , italic_y ) âˆˆ italic_D } | Following the previous literature [[42](https://arxiv.org/html/2405.19902v1#bib.bib42), [15](https://arxiv.org/html/2405.19902v1#bib.bib15), [14](https://arxiv.org/html/2405.19902v1#bib.bib14)], we presume the diagonally dominant condition, i.e., Prâ¢(y~=i|y=i)>Prâ¢(y~=j|y=i),âˆ€iâ‰ jformulae-sequencePr~ğ‘¦conditionalğ‘–ğ‘¦ğ‘–Pr~ğ‘¦conditionalğ‘—ğ‘¦ğ‘–for-allğ‘–ğ‘—\mathrm{Pr}(\tilde{y}=i|y=i)>\mathrm{Pr}(\tilde{y}=j|y=i),\forall i\neq jroman_Pr ( over~ start_ARG italic_y end_ARG = italic_i | italic_y = italic_i ) > roman_Pr ( over~ start_ARG italic_y end_ARG = italic_j | italic_y = italic_i ) , âˆ€ italic_i â‰  italic_j, which indicates that correct labels should not be overwhelmed by the false ones. With this condition of Î·<1âˆ’1Cğœ‚11ğ¶\eta<1-\frac{1}{C}italic_Î· < 1 - divide start_ARG 1 end_ARG start_ARG italic_C end_ARG, we have the following proposition.

######  Proposition 1 (Lower bound of Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT)

Let Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT denote the noise rate of the corrupted dataset. Given the diagonally dominant condition, i,e., Î·<1âˆ’1Cğœ‚11ğ¶\eta<1-\frac{1}{C}italic_Î· < 1 - divide start_ARG 1 end_ARG start_ARG italic_C end_ARG, for any Î³âˆˆ(0,1]ğ›¾01\gamma\in{\left(0,1\right]}italic_Î³ âˆˆ ( 0 , 1 ], Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT has a lower bound of 1âˆ’1C11ğ¶1-\frac{1}{C}1 - divide start_ARG 1 end_ARG start_ARG italic_C end_ARG.

The proof is presented in Appendix C, from which we can derive Î·<Î·Î³ğœ‚subscriptğœ‚ğ›¾\eta<\eta_{\gamma}italic_Î· < italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT.

###  4.3 Training dynamics generation

####  4.3.1 Training dynamics

The training dynamics indicates a modelâ€™s behavior on individual instances during the training, quantitatively describing the training process [[44](https://arxiv.org/html/2405.19902v1#bib.bib44), [47](https://arxiv.org/html/2405.19902v1#bib.bib47)]. Concretely, the training dynamics is defined as the trajectory of training signals derived from a modelâ€™s output across the training epochs. In the literature, various types of training signals [[66](https://arxiv.org/html/2405.19902v1#bib.bib66), [44](https://arxiv.org/html/2405.19902v1#bib.bib44), [1](https://arxiv.org/html/2405.19902v1#bib.bib1)] have been employed for analyzing the modelâ€™s behavior.

Given a classifier fğ‘“fitalic_f, let fâ¢(ğ±)âˆˆâ„Cğ‘“ğ±superscriptâ„ğ¶f(\mathbf{x})\in\mathbb{R}^{C}italic_f ( bold_x ) âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT denote the output logits of an instance ğ±ğ±\mathbf{x}bold_x for Cğ¶Citalic_C classes. Let tğ‘¡titalic_t be a transformation function that maps Cğ¶Citalic_C logits to a scalar training signal. In this paper, we use quantized logit difference as the training signal.222We provide a detailed analysis of various training signals for identifying incorrectly labeled instances in Appendix B.3 It quantizes the difference between a logit [[36](https://arxiv.org/html/2405.19902v1#bib.bib36)] of a given label and the largest logit among the remaining classes, i.e., tâ¢(fâ¢(ğ±),y~)=signâ¢(fy~â¢(ğ±)âˆ’maxcâ‰ y~â¡fcâ¢(ğ±)),ğ‘¡ğ‘“ğ±~ğ‘¦signsubscriptğ‘“~ğ‘¦ğ±subscriptğ‘~ğ‘¦subscriptğ‘“ğ‘ğ±t(f(\mathbf{x}),\tilde{y})=\text{sign}(f_{\tilde{y}}(\mathbf{x})-\max_{c\neq% \tilde{y}}f_{c}(\mathbf{x})),italic_t ( italic_f ( bold_x ) , over~ start_ARG italic_y end_ARG ) = sign ( italic_f start_POSTSUBSCRIPT over~ start_ARG italic_y end_ARG end_POSTSUBSCRIPT ( bold_x ) - roman_max start_POSTSUBSCRIPT italic_c â‰  over~ start_ARG italic_y end_ARG end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( bold_x ) ) , where fcâ¢(ğ±)subscriptğ‘“ğ‘ğ±f_{c}(\mathbf{x})italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( bold_x ) denotes the logit for class cğ‘citalic_c, and signâ¢(ğ±)=1signğ±1\text{sign}(\mathbf{x})=1sign ( bold_x ) = 1 or -1 if ğ±>=0ğ±0\mathbf{x}>=0bold_x > = 0 or <0absent0<0< 0, respectively. The training dynamics for an instance ğ±ğ±\mathbf{x}bold_x is defined as

| ğ­ğ±=[t(1)(f(ğ±),y~),..,t(E)(f(ğ±),y~)],\mathbf{t}_{\mathbf{x}}=[t^{(1)}(f(\mathbf{x}),\tilde{y}),..,t^{(E)}(f(\mathbf% {x}),\tilde{y})],bold_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = [ italic_t start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT ( italic_f ( bold_x ) , over~ start_ARG italic_y end_ARG ) , . . , italic_t start_POSTSUPERSCRIPT ( italic_E ) end_POSTSUPERSCRIPT ( italic_f ( bold_x ) , over~ start_ARG italic_y end_ARG ) ] , |  | (1)  
---|---|---|---  
  
where t(e)â¢(fâ¢(ğ±),y~)superscriptğ‘¡ğ‘’ğ‘“ğ±~ğ‘¦t^{(e)}(f(\mathbf{x}),\tilde{y})italic_t start_POSTSUPERSCRIPT ( italic_e ) end_POSTSUPERSCRIPT ( italic_f ( bold_x ) , over~ start_ARG italic_y end_ARG ) denotes the training signal computed at epoch eğ‘’eitalic_e, and Eğ¸Eitalic_E is the maximum number of training epochs. For the sake of convenience, we denote ğ­ğ±subscriptğ­ğ±\mathbf{t}_{\mathbf{x}}bold_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT and tğ±(e)subscriptsuperscriptğ‘¡ğ‘’ğ±t^{(e)}_{\mathbf{x}}italic_t start_POSTSUPERSCRIPT ( italic_e ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT as an abbreviation for ğ­â¢(ğ±,y~;f)ğ­ğ±~ğ‘¦ğ‘“\mathbf{t}(\mathbf{x},\tilde{y};f)bold_t ( bold_x , over~ start_ARG italic_y end_ARG ; italic_f ) and t(e)â¢(fâ¢(ğ±),y~)superscriptğ‘¡ğ‘’ğ‘“ğ±~ğ‘¦t^{(e)}(f(\mathbf{x}),\tilde{y})italic_t start_POSTSUPERSCRIPT ( italic_e ) end_POSTSUPERSCRIPT ( italic_f ( bold_x ) , over~ start_ARG italic_y end_ARG ), respectively.

####  4.3.2 Dynamics generation for noisy label detection

We generate training dynamics for both the original and the corrupted datasets. Specifically, we train a classifier by minimizing the classification loss on D~~ğ·\widetilde{D}over~ start_ARG italic_D end_ARG and DÂ¯Â¯ğ·\bar{D}overÂ¯ start_ARG italic_D end_ARG:

| 1|D~|â¢âˆ‘(ğ±,y~)âˆˆD~â„“câ¢eâ¢(fâ¢(ğ±),y~)+1|DÂ¯|â¢âˆ‘(ğ±Â¯,yÂ¯)âˆˆDÂ¯â„“câ¢eâ¢(fâ¢(ğ±Â¯),yÂ¯),1~ğ·subscriptğ±~ğ‘¦~ğ·subscriptâ„“ğ‘ğ‘’ğ‘“ğ±~ğ‘¦1Â¯ğ·subscriptÂ¯ğ±Â¯ğ‘¦Â¯ğ·subscriptâ„“ğ‘ğ‘’ğ‘“Â¯ğ±Â¯ğ‘¦\frac{1}{|\widetilde{D}|}\sum_{(\mathbf{x},\tilde{y})\in{\widetilde{D}}}{\ell_% {ce}(f(\mathbf{x}),\tilde{y})}+\frac{1}{|\bar{D}|}\sum_{(\bar{\mathbf{x}},\bar% {y})\in{\bar{D}}}{\ell_{ce}\left(f(\bar{\mathbf{x}}),\bar{y}\right)},divide start_ARG 1 end_ARG start_ARG | over~ start_ARG italic_D end_ARG | end_ARG âˆ‘ start_POSTSUBSCRIPT ( bold_x , over~ start_ARG italic_y end_ARG ) âˆˆ over~ start_ARG italic_D end_ARG end_POSTSUBSCRIPT roman_â„“ start_POSTSUBSCRIPT italic_c italic_e end_POSTSUBSCRIPT ( italic_f ( bold_x ) , over~ start_ARG italic_y end_ARG ) + divide start_ARG 1 end_ARG start_ARG | overÂ¯ start_ARG italic_D end_ARG | end_ARG âˆ‘ start_POSTSUBSCRIPT ( overÂ¯ start_ARG bold_x end_ARG , overÂ¯ start_ARG italic_y end_ARG ) âˆˆ overÂ¯ start_ARG italic_D end_ARG end_POSTSUBSCRIPT roman_â„“ start_POSTSUBSCRIPT italic_c italic_e end_POSTSUBSCRIPT ( italic_f ( overÂ¯ start_ARG bold_x end_ARG ) , overÂ¯ start_ARG italic_y end_ARG ) , |  | (2)  
---|---|---|---  
  
where â„“câ¢esubscriptâ„“ğ‘ğ‘’\ell_{ce}roman_â„“ start_POSTSUBSCRIPT italic_c italic_e end_POSTSUBSCRIPT is the softmax cross-entropy loss. For each instance ğ±ğ±\mathbf{x}bold_x, we obtain a training dynamics ğ­ğ±âˆˆâ„Esubscriptğ­ğ±superscriptâ„ğ¸\mathbf{t}_{\mathbf{x}}\in\mathbb{R}^{E}bold_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT as specified in Eq. ([1](https://arxiv.org/html/2405.19902v1#S4.E1 "Equation 1 â€£ 4.3.1 Training dynamics â€£ 4.3 Training dynamics generation â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")) by tracking tğ±(e)subscriptsuperscriptğ‘¡ğ‘’ğ±t^{(e)}_{\mathbf{x}}italic_t start_POSTSUPERSCRIPT ( italic_e ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT over the course of training epochs Eğ¸Eitalic_E. Training dynamics of the original and the corrupted datasets are denoted by T~:={ğ­ğ±|(ğ±,y~)âˆˆD~}assign~ğ‘‡conditional-setsubscriptğ­ğ±ğ±~ğ‘¦~ğ·\widetilde{T}:=\\{\mathbf{t}_{\mathbf{x}}|(\mathbf{x},\tilde{y})\in{\widetilde{% D}}\\}over~ start_ARG italic_T end_ARG := { bold_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT | ( bold_x , over~ start_ARG italic_y end_ARG ) âˆˆ over~ start_ARG italic_D end_ARG } and TÂ¯:={ğ­ğ±Â¯|(ğ±Â¯,yÂ¯)âˆˆDÂ¯}assignÂ¯ğ‘‡conditional-setsubscriptğ­Â¯ğ±Â¯ğ±Â¯ğ‘¦Â¯ğ·\bar{T}:=\\{\mathbf{t}_{\bar{\mathbf{x}}}|(\bar{\mathbf{x}},\bar{y})\in{\bar{D}}\\}overÂ¯ start_ARG italic_T end_ARG := { bold_t start_POSTSUBSCRIPT overÂ¯ start_ARG bold_x end_ARG end_POSTSUBSCRIPT | ( overÂ¯ start_ARG bold_x end_ARG , overÂ¯ start_ARG italic_y end_ARG ) âˆˆ overÂ¯ start_ARG italic_D end_ARG }, respectively.

###  4.4 Noisy label detection via dynamics clustering

We use a clustering approach to identify incorrectly labeled instances within the original dataset. Using a dynamics encoder, we encode the generated dynamics and progressively find clusters of correctly and incorrectly labeled instances in the representation space. The dynamics clustering iterates two key processes: (1) identifications of incorrectly labeled instances (Sec. [4.4.1](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS1 "4.4.1 Identification of incorrectly labeled instances â€£ 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")), and (2) learning distinct representations for each cluster (Sec. [4.4.2](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS2 "4.4.2 Learning discriminative patterns in dynamics â€£ 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")). The clustering quality is assessed by a newly introduced validation metric by leveraging the corrupted dataset without a clean validation dataset (Sec. [4.4.3](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS3 "4.4.3 Validation metric â€£ 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")).

####  4.4.1 Identification of incorrectly labeled instances

Cluster initialization.  Given a training dynamics ğ­ğ±subscriptğ­ğ±\mathbf{t}_{\mathbf{x}}bold_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT, a dynamics encoder generates its representation, i.e., ğ³ğ±=Encâ¢(ğ­ğ±)âˆˆâ„dğ³subscriptğ³ğ±Encsubscriptğ­ğ±superscriptâ„subscriptğ‘‘ğ³\mathbf{z}_{\mathbf{x}}=\mathrm{Enc}(\mathbf{t}_{\mathbf{x}})\in\mathbb{R}^{d_% {\mathbf{z}}}bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = roman_Enc ( bold_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT bold_z end_POSTSUBSCRIPT end_POSTSUPERSCRIPT. Let Z~~ğ‘\widetilde{Z}over~ start_ARG italic_Z end_ARG and ZÂ¯Â¯ğ‘\bar{Z}overÂ¯ start_ARG italic_Z end_ARG denote the set of dynamics representations of the original and the corrupted datasets, respectively. We first introduce trainable parameters for centroids of noisy and clean clusters, i.e., ğnâ¢oâ¢iâ¢sâ¢y,ğcâ¢lâ¢eâ¢aâ¢nâˆˆâ„dğ³subscriptğğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğğ‘ğ‘™ğ‘’ğ‘ğ‘›superscriptâ„subscriptğ‘‘ğ³\bm{\mu}_{noisy},\,\bm{\mu}_{clean}\in\mathbb{R}^{d_{\mathbf{z}}}bold_italic_Î¼ start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT , bold_italic_Î¼ start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT bold_z end_POSTSUBSCRIPT end_POSTSUPERSCRIPT. We initialize ğnâ¢oâ¢iâ¢sâ¢ysubscriptğğ‘›ğ‘œğ‘–ğ‘ ğ‘¦\bm{\mu}_{noisy}bold_italic_Î¼ start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT as the average representation of the corrupted instances ZÂ¯Â¯ğ‘\bar{Z}overÂ¯ start_ARG italic_Z end_ARG, while ğcâ¢lâ¢eâ¢aâ¢nsubscriptğğ‘ğ‘™ğ‘’ğ‘ğ‘›\bm{\mu}_{clean}bold_italic_Î¼ start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT is initialized as the average representation of the original instances Z~~ğ‘\widetilde{Z}over~ start_ARG italic_Z end_ARG. Note that this initialization is conducted only once at the beginning of the dynamics clustering step.

Noisy label identification.  We determine whether each instance ğ±ğ±\mathbf{x}bold_x has been incorrectly labeled based on its assignment probability to the noisy cluster. The assignment probability is computed based on the similarity between ğ³ğ±subscriptğ³ğ±\mathbf{z_{x}}bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT and the noisy clusterâ€™s centroid ğnâ¢oâ¢iâ¢sâ¢ysubscriptğğ‘›ğ‘œğ‘–ğ‘ ğ‘¦\bm{\mu}_{noisy}bold_italic_Î¼ start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT. We employ a kernel function based on the Studentâ€™s tğ‘¡titalic_t-distribution [[46](https://arxiv.org/html/2405.19902v1#bib.bib46)] with one degree of freedom as follows:

| qnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±)subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±\displaystyle q_{noisy}(\mathbf{z_{x}})italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) | =(1+dâ¢(ğ³ğ±,ğnâ¢oâ¢iâ¢sâ¢y))âˆ’1(1+dâ¢(ğ³ğ±,ğnâ¢oâ¢iâ¢sâ¢y))âˆ’1+(1+dâ¢(ğ³ğ±,ğcâ¢lâ¢eâ¢aâ¢n))âˆ’1,absentsuperscript1ğ‘‘subscriptğ³ğ±subscriptğğ‘›ğ‘œğ‘–ğ‘ ğ‘¦1superscript1ğ‘‘subscriptğ³ğ±subscriptğğ‘›ğ‘œğ‘–ğ‘ ğ‘¦1superscript1ğ‘‘subscriptğ³ğ±subscriptğğ‘ğ‘™ğ‘’ğ‘ğ‘›1\displaystyle={\frac{{(1+d(\mathrm{\mathbf{z_{x}}},\bm{\mu}_{noisy}))^{-1}}}{{% (1+d(\mathrm{\mathbf{z_{x}}},\bm{\mu}_{noisy}))^{-1}}+{(1+d(\mathrm{\mathbf{z_% {x}}},\bm{\mu}_{clean}))^{-1}}}},= divide start_ARG ( 1 + italic_d ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT , bold_italic_Î¼ start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT end_ARG start_ARG ( 1 + italic_d ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT , bold_italic_Î¼ start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT + ( 1 + italic_d ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT , bold_italic_Î¼ start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT end_ARG , |   
---|---|---|---  
| qcâ¢lâ¢eâ¢aâ¢nâ¢(ğ³ğ±)subscriptğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ³ğ±\displaystyle q_{clean}(\mathbf{z_{x}})italic_q start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) | =1âˆ’qnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±),absent1subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±\displaystyle=1-q_{noisy}(\mathbf{z_{x}}),= 1 - italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) , |  | (3)  
  
where dâ¢(ğš,ğ›)=1âˆ’âŸ¨ğš,ğ›âŸ©â€–ğšâ€–2â‹…â€–ğ›â€–2ğ‘‘ğšğ›1ğšğ›â‹…subscriptnormğš2subscriptnormğ›2d(\mathbf{a},\mathbf{b})=1-\frac{\langle\mathbf{a},\mathbf{b}\rangle}{||% \mathbf{a}||_{2}\cdot||\mathbf{b}||_{2}}italic_d ( bold_a , bold_b ) = 1 - divide start_ARG âŸ¨ bold_a , bold_b âŸ© end_ARG start_ARG | | bold_a | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT â‹… | | bold_b | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG. Based on the assignment probability, we regard an instance as incorrectly labeled when its probability to the noisy cluster is predominant.

| vâ¢(ğ³ğ±):=ğŸ™â¢[qnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±)>qcâ¢lâ¢eâ¢aâ¢nâ¢(ğ³ğ±)],assignğ‘£subscriptğ³ğ±1delimited-[]subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±subscriptğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ³ğ±v(\mathbf{z_{x}}):=\mathbbm{1}[q_{noisy}(\mathbf{z_{x}})>q_{clean}(\mathbf{z_{% x}})],italic_v ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) := blackboard_1 [ italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) > italic_q start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) ] , |  | (4)  
---|---|---|---  
  
vâ¢(ğ³ğ±)=1ğ‘£subscriptğ³ğ±1v(\mathbf{z_{x}})=1italic_v ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) = 1 indicates that ğ±ğ±\mathbf{x}bold_x is predicted to have a noisy label.

####  4.4.2 Learning discriminative patterns in dynamics

We introduce the strategy of inducing two distinguishable clusters (each for correctly and incorrectly labeled instances) in the dynamics representation space. We propose two types of losses for (1) high cluster cohesion and (2) cluster alignment between original and corrupted instances.

Clustering loss.  We introduce a clustering loss to make the clusters more distinguishable. We enhance cluster cohesion by adjusting each instanceâ€™s representation to be closer to a centroid through a self-enhancing target distribution. The target distribution is constructed by amplifying the predicted assignment probability [[58](https://arxiv.org/html/2405.19902v1#bib.bib58)] as follows:

| pnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±)subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±\displaystyle p_{noisy}(\mathbf{z_{x}})italic_p start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) | =qnâ¢oâ¢iâ¢sâ¢y2â¢(ğ³ğ±)/snâ¢oâ¢iâ¢sâ¢yqnâ¢oâ¢iâ¢sâ¢y2â¢(ğ³ğ±)/snâ¢oâ¢iâ¢sâ¢y+qcâ¢lâ¢eâ¢aâ¢n2â¢(ğ³ğ±)/scâ¢lâ¢eâ¢aâ¢n,absentsuperscriptsubscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦2subscriptğ³ğ±subscriptğ‘ ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦superscriptsubscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦2subscriptğ³ğ±subscriptğ‘ ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦superscriptsubscriptğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›2subscriptğ³ğ±subscriptğ‘ ğ‘ğ‘™ğ‘’ğ‘ğ‘›\displaystyle={\frac{{q_{noisy}^{2}(\mathbf{z_{x}})/s_{noisy}}}{q_{noisy}^{2}(% \mathbf{z_{x}})/s_{noisy}+q_{clean}^{2}(\mathbf{z_{x}})/s_{clean}}},= divide start_ARG italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) / italic_s start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT end_ARG start_ARG italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) / italic_s start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT + italic_q start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) / italic_s start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT end_ARG , |   
---|---|---|---  
| pcâ¢lâ¢eâ¢aâ¢nâ¢(ğ³ğ±)subscriptğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ³ğ±\displaystyle p_{clean}(\mathbf{z_{x}})italic_p start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) | =1âˆ’pnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±),absent1subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±\displaystyle=1-p_{noisy}(\mathbf{z_{x}}),= 1 - italic_p start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) , |  | (5)  
  
where snâ¢oâ¢iâ¢sâ¢y=âˆ‘ğ³âˆˆZ~âˆªZÂ¯qnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³)subscriptğ‘ ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³~ğ‘Â¯ğ‘subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦ğ³s_{noisy}=\sum_{\mathbf{z}\in{\widetilde{Z}\cup\bar{Z}}}q_{noisy}(\mathbf{z})italic_s start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT = âˆ‘ start_POSTSUBSCRIPT bold_z âˆˆ over~ start_ARG italic_Z end_ARG âˆª overÂ¯ start_ARG italic_Z end_ARG end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z ) and scâ¢lâ¢eâ¢aâ¢n=âˆ‘ğ³âˆˆZ~âˆªZÂ¯qcâ¢lâ¢eâ¢aâ¢nâ¢(ğ³)subscriptğ‘ ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ³~ğ‘Â¯ğ‘subscriptğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›ğ³s_{clean}=\sum_{\mathbf{z}\in{\widetilde{Z}\cup\bar{Z}}}q_{clean}(\mathbf{z})italic_s start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT = âˆ‘ start_POSTSUBSCRIPT bold_z âˆˆ over~ start_ARG italic_Z end_ARG âˆª overÂ¯ start_ARG italic_Z end_ARG end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT ( bold_z ). Then, we minimize the KL divergence between the cluster assignment distribution ğªâ¢(ğ³ğ±)=[qnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±),qcâ¢lâ¢eâ¢aâ¢nâ¢(ğ³ğ±)]ğªsubscriptğ³ğ±subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±subscriptğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ³ğ±\mathbf{q}(\mathbf{z_{x}})=[q_{noisy}(\mathbf{z_{x}}),\,q_{clean}(\mathbf{z_{x% }})]bold_q ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) = [ italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) , italic_q start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) ] and the target distribution ğ©â¢(ğ³ğ±)=[pnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±),pcâ¢lâ¢eâ¢aâ¢nâ¢(ğ³ğ±)]ğ©subscriptğ³ğ±subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±subscriptğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ³ğ±\mathbf{p}(\mathbf{z_{x}})=[p_{noisy}(\mathbf{z_{x}}),\,p_{clean}(\mathbf{z_{x% }})]bold_p ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) = [ italic_p start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) , italic_p start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) ] as follows:

| â„’câ¢lâ¢uâ¢sâ¢tâ¢eâ¢r=âˆ‘ğ³ğ±âˆˆZ~âˆªZÂ¯KL(ğ©(ğ³ğ±)||ğª(ğ³ğ±)).\mathcal{L}_{cluster}=\sum_{\mathbf{z_{x}}\in{\widetilde{Z}\cup\bar{Z}}}% \mathrm{KL}(\mathbf{p}(\mathbf{z_{x}})||\mathbf{q}(\mathbf{z_{x}})).caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_u italic_s italic_t italic_e italic_r end_POSTSUBSCRIPT = âˆ‘ start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ over~ start_ARG italic_Z end_ARG âˆª overÂ¯ start_ARG italic_Z end_ARG end_POSTSUBSCRIPT roman_KL ( bold_p ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) | | bold_q ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) ) . |  | (6)  
---|---|---|---  
  
Alignment loss.  We introduce an alignment loss that aligns the representation from each clusterâ€™s original and corrupted datasets. We hypothesize333It is theoretically proved in [[34](https://arxiv.org/html/2405.19902v1#bib.bib34)] that symmetric noise is relatively easy to identify among various noise types with diverse difficulty levels. Consequently, incorrectly labeled instances in the corrupted dataset exhibit more distinctive dynamics patterns than those in the original data, i.e., a red dashed line is farther away from blue lines than a red line in the 3rd step of Fig.[1](https://arxiv.org/html/2405.19902v1#S2.F1 "Figure 1 â€£ 2 Related Work â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") (left). From this perspective, the mismatched noise types between the original and the corrupted datasets positively impact the clustering process by adopting alignment loss, which forces a red line to be aligned with a red dashed line in the 3rd step of Fig.[1](https://arxiv.org/html/2405.19902v1#S2.F1 "Figure 1 â€£ 2 Related Work â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") (right).

Instances in the original dataset predicted as noisy and clean are denoted by Z~nâ¢oâ¢iâ¢sâ¢y={ğ³ğ±âˆˆZ~|vâ¢(ğ³ğ±)=1}subscript~ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦conditional-setsubscriptğ³ğ±~ğ‘ğ‘£subscriptğ³ğ±1\widetilde{Z}_{noisy}=\\{\mathbf{z_{x}}\in\widetilde{Z}|v(\mathbf{z_{x}})=1\\}over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT = { bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ over~ start_ARG italic_Z end_ARG | italic_v ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) = 1 } and Z~câ¢lâ¢eâ¢aâ¢n={ğ³ğ±âˆˆZ~|vâ¢(ğ³ğ±)=0}subscript~ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›conditional-setsubscriptğ³ğ±~ğ‘ğ‘£subscriptğ³ğ±0\widetilde{Z}_{clean}=\\{\mathbf{z_{x}}\in\widetilde{Z}|v(\mathbf{z_{x}})=0\\}over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT = { bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ over~ start_ARG italic_Z end_ARG | italic_v ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) = 0 }, respectively. Analogously, for the corrupted dataset, we obtain ZÂ¯nâ¢oâ¢iâ¢sâ¢y={ğ³ğ±âˆˆZÂ¯|vâ¢(ğ³ğ±)=1}subscriptÂ¯ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦conditional-setsubscriptğ³ğ±Â¯ğ‘ğ‘£subscriptğ³ğ±1\bar{Z}_{noisy}=\\{\mathbf{z_{x}}\in\bar{Z}|v(\mathbf{z_{x}})=1\\}overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT = { bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ overÂ¯ start_ARG italic_Z end_ARG | italic_v ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) = 1 } and ZÂ¯câ¢lâ¢eâ¢aâ¢n={ğ³ğ±âˆˆZÂ¯|vâ¢(ğ³ğ±)=0}subscriptÂ¯ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›conditional-setsubscriptğ³ğ±Â¯ğ‘ğ‘£subscriptğ³ğ±0\bar{Z}_{clean}=\\{\mathbf{z_{x}}\in\bar{Z}|v(\mathbf{z_{x}})=0\\}overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT = { bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ overÂ¯ start_ARG italic_Z end_ARG | italic_v ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) = 0 }. Then, we employ the alignment loss to reduce the discrepancy between the representations of the original dataset and the corrupted dataset as follows:

| â„’aâ¢lâ¢iâ¢gâ¢nnsuperscriptsubscriptâ„’ğ‘ğ‘™ğ‘–ğ‘”ğ‘›ğ‘›\displaystyle\mathcal{L}_{align}^{n}caligraphic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT | =dâ¢(1|Z~nâ¢oâ¢iâ¢sâ¢y|â¢âˆ‘ğ³ğ±âˆˆZ~nâ¢oâ¢iâ¢sâ¢yğ³ğ±,1|ZÂ¯nâ¢oâ¢iâ¢sâ¢y|â¢âˆ‘ğ³ğ±âˆˆZÂ¯nâ¢oâ¢iâ¢sâ¢yğ³ğ±),absentğ‘‘1subscript~ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptsubscriptğ³ğ±subscript~ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±1subscriptÂ¯ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptsubscriptğ³ğ±subscriptÂ¯ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±\displaystyle=d\Big{(}\frac{1}{|\widetilde{Z}_{noisy}|}\sum_{\mathbf{z_{x}}\in% \widetilde{Z}_{noisy}}\mathbf{z_{x}},\frac{1}{|\bar{Z}_{noisy}|}\sum_{\mathbf{% z_{x}}\in\bar{Z}_{noisy}}\mathbf{z_{x}}\Big{)},= italic_d ( divide start_ARG 1 end_ARG start_ARG | over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT | end_ARG âˆ‘ start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT , divide start_ARG 1 end_ARG start_ARG | overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT | end_ARG âˆ‘ start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) , |   
---|---|---|---  
| â„’aâ¢lâ¢iâ¢gâ¢ncsuperscriptsubscriptâ„’ğ‘ğ‘™ğ‘–ğ‘”ğ‘›ğ‘\displaystyle\mathcal{L}_{align}^{c}caligraphic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT | =dâ¢(1|Z~câ¢lâ¢eâ¢aâ¢n|â¢âˆ‘ğ³ğ±âˆˆZ~câ¢lâ¢eâ¢aâ¢nğ³ğ±,1|ZÂ¯câ¢lâ¢eâ¢aâ¢n|â¢âˆ‘ğ³ğ±âˆˆZÂ¯câ¢lâ¢eâ¢aâ¢nğ³ğ±),absentğ‘‘1subscript~ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptsubscriptğ³ğ±subscript~ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ³ğ±1subscriptÂ¯ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptsubscriptğ³ğ±subscriptÂ¯ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ³ğ±\displaystyle=d\Big{(}\frac{1}{|\widetilde{Z}_{clean}|}\sum_{\mathbf{z_{x}}\in% \widetilde{Z}_{clean}}\mathbf{z_{x}},\frac{1}{|\bar{Z}_{clean}|}\sum_{\mathbf{% z_{x}}\in\bar{Z}_{clean}}\mathbf{z_{x}}\Big{)},= italic_d ( divide start_ARG 1 end_ARG start_ARG | over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT | end_ARG âˆ‘ start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT , divide start_ARG 1 end_ARG start_ARG | overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT | end_ARG âˆ‘ start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) , |   
| â„’aâ¢lâ¢iâ¢gâ¢nsubscriptâ„’ğ‘ğ‘™ğ‘–ğ‘”ğ‘›\displaystyle\mathcal{L}_{align}caligraphic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT | =12â¢(â„’aâ¢lâ¢iâ¢gâ¢nn+â„’aâ¢lâ¢iâ¢gâ¢nc).absent12superscriptsubscriptâ„’ğ‘ğ‘™ğ‘–ğ‘”ğ‘›ğ‘›superscriptsubscriptâ„’ğ‘ğ‘™ğ‘–ğ‘”ğ‘›ğ‘\displaystyle={\frac{1}{2}}(\mathcal{L}_{align}^{n}+\mathcal{L}_{align}^{c}).= divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( caligraphic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT + caligraphic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT ) . |  | (7)  
  
Optimization.  To sum up, the dynamics encoder is optimized by minimizing the following loss:

| â„’=â„’câ¢lâ¢uâ¢sâ¢tâ¢eâ¢r+Î±â¢â„’aâ¢lâ¢iâ¢gâ¢n,â„’subscriptâ„’ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ›¼subscriptâ„’ğ‘ğ‘™ğ‘–ğ‘”ğ‘›\mathcal{L}=\mathcal{L}_{cluster}+\alpha\mathcal{L}_{align},caligraphic_L = caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_u italic_s italic_t italic_e italic_r end_POSTSUBSCRIPT + italic_Î± caligraphic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT , |  | (8)  
---|---|---|---  
  
where Î±ğ›¼\alphaitalic_Î± is a hyperparameter that controls the impact of the alignment loss.

####  4.4.3 Validation metric

One practical challenge in training the dynamics encoder is determining an appropriate stopping point in the absence of ground-truth annotations of clean and noisy labels for validation. As a solution, we introduce a new validation metric for the dynamics encoder to estimate its detection performance indirectly. For noisy label detection, we aim to maximize (a) the assignment of incorrectly labeled instances to the noisy cluster while minimizing (b) the assignment of correctly labeled instances to the noisy cluster. Intuitively, in an ideally clustered space, the difference between (a) and (b) needs to be maximized.

Since we cannot access the ground-truth annotations to compute (a) and (b), we use the most representative instances as a workaround. Considering the corrupted dataset has a higher noise rate than the original dataset, we emulate (a) using instances predicted as noisy among the corrupted dataset, i.e., ZÂ¯nâ¢oâ¢iâ¢sâ¢ysubscriptÂ¯ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦\bar{Z}_{noisy}overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT. Similarly, (b) is emulated using instances predicted as clean among the original dataset with a lower noise rate, i.e., Z~câ¢lâ¢eâ¢aâ¢nsubscript~ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›\widetilde{Z}_{clean}over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT. Our validation metric is defined as the difference between two emulated values as

| (âˆ‘ğ³ğ±âˆˆZÂ¯nâ¢oâ¢iâ¢sâ¢yqnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±)|ZÂ¯nâ¢oâ¢iâ¢sâ¢y|âˆ’âˆ‘ğ³ğ±âˆˆZ~câ¢lâ¢eâ¢aâ¢nqnâ¢oâ¢iâ¢sâ¢yâ¢(ğ³ğ±)|Z~câ¢lâ¢eâ¢aâ¢n|)2.superscriptsubscriptsubscriptğ³ğ±subscriptÂ¯ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±subscriptÂ¯ğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptsubscriptğ³ğ±subscript~ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›subscriptğ‘ğ‘›ğ‘œğ‘–ğ‘ ğ‘¦subscriptğ³ğ±subscript~ğ‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›2\Big{(}\sum_{\mathbf{z}_{\mathbf{x}}\in\bar{Z}_{noisy}}\frac{q_{noisy}(\mathbf% {z_{x}})}{|\bar{Z}_{noisy}|}-\sum_{\mathbf{z_{x}}\in\widetilde{Z}_{clean}}% \frac{q_{noisy}(\mathbf{z_{x}})}{|\widetilde{Z}_{clean}|}\Big{)}^{2}.( âˆ‘ start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT end_POSTSUBSCRIPT divide start_ARG italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) end_ARG start_ARG | overÂ¯ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT | end_ARG - âˆ‘ start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âˆˆ over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT divide start_ARG italic_q start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_y end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ) end_ARG start_ARG | over~ start_ARG italic_Z end_ARG start_POSTSUBSCRIPT italic_c italic_l italic_e italic_a italic_n end_POSTSUBSCRIPT | end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT . |  | (9)  
---|---|---|---  
  
The larger value indicates the better clustering quality for noisy label detection. Compared to the conventional metrics for assessing cluster separation [[39](https://arxiv.org/html/2405.19902v1#bib.bib39), [10](https://arxiv.org/html/2405.19902v1#bib.bib10)], this metric is tailored for our DynaCor framework and provides a more effective measure of noisy label detection efficacy.

##  5 Experiments

Dataset | CIFAR-10 | CIFAR-100 |   
---|---|---|---  
Noise type | Sym. | Asym. | Inst. | Agg. | Worst | Sym. | Asym. | Inst. | Human | Avg.  
Noise rate (Î·ğœ‚\etaitalic_Î·) | 0.6 | 0.3 | 0.4 | 0.09 | 0.4 | 0.6 | 0.3 | 0.4 | 0.4 |   
Avg.Encoder |  98.0 Â±plus-or-minus\pmÂ± 0.03 | 89.7 Â±plus-or-minus\pmÂ± 0.14 | 22.4 Â±plus-or-minus\pmÂ± 33.5 | 67.3 Â±plus-or-minus\pmÂ± 0.42 |  92.8 Â±plus-or-minus\pmÂ± 0.11 |  96.7 Â±plus-or-minus\pmÂ± 0.07 | 74.9 Â±plus-or-minus\pmÂ± 0.17 | 76.8 Â±plus-or-minus\pmÂ± 0.51 | 79.5 Â±plus-or-minus\pmÂ± 0.31 | 77.6  
AUM | 95.7 Â±plus-or-minus\pmÂ± 0.07 | 86.5 Â±plus-or-minus\pmÂ± 0.18 | 81.9 Â±plus-or-minus\pmÂ± 0.72 | 74.0 Â±plus-or-minus\pmÂ± 0.16 | 88.7 Â±plus-or-minus\pmÂ± 0.19 | 96.4 Â±plus-or-minus\pmÂ± 0.10 | 74.7 Â±plus-or-minus\pmÂ± 0.21 | 81.2 Â±plus-or-minus\pmÂ± 0.25 | 74.6 Â±plus-or-minus\pmÂ± 1.25 | 83.7  
CL | 96.6 Â±plus-or-minus\pmÂ± 0.04 |  94.0 Â±plus-or-minus\pmÂ± 0.10 | 82.0 Â±plus-or-minus\pmÂ± 0.21 | 68.6 Â±plus-or-minus\pmÂ± 0.33 | 88.3 Â±plus-or-minus\pmÂ± 0.11 | 88.0 Â±plus-or-minus\pmÂ± 0.08 | 68.6 Â±plus-or-minus\pmÂ± 0.16 | 75.9 Â±plus-or-minus\pmÂ± 0.12 | 71.9 Â±plus-or-minus\pmÂ± 0.10 | 81.5  
CORES | 97.7 Â±plus-or-minus\pmÂ± 0.03 | 5.00 Â±plus-or-minus\pmÂ± 0.33 | 19.2 Â±plus-or-minus\pmÂ± 0.10 |  80.5 Â±plus-or-minus\pmÂ± 0.09 | 77.5 Â±plus-or-minus\pmÂ± 0.09 | 83.9 Â±plus-or-minus\pmÂ± 0.20 | 21.9 Â±plus-or-minus\pmÂ± 0.32 | 36.7 Â±plus-or-minus\pmÂ± 0.41 | 36.0 Â±plus-or-minus\pmÂ± 0.12 | 50.9  
SIMIFEAT-V | 95.1 Â±plus-or-minus\pmÂ± 0.06 | 89.4 Â±plus-or-minus\pmÂ± 0.08 | 88.1 Â±plus-or-minus\pmÂ± 0.11 | 79.6 Â±plus-or-minus\pmÂ± 0.13 | 91.6 Â±plus-or-minus\pmÂ± 0.06 | 86.0 Â±plus-or-minus\pmÂ± 0.09 | 73.8 Â±plus-or-minus\pmÂ± 0.07 | 80.5 Â±plus-or-minus\pmÂ± 0.09 | 77.1 Â±plus-or-minus\pmÂ± 0.12 | 84.6  
SIMIFEAT-R | 96.1 Â±plus-or-minus\pmÂ± 1.41 | 88.9 Â±plus-or-minus\pmÂ± 0.14 | 91.2 Â±plus-or-minus\pmÂ± 0.07 | 79.6 Â±plus-or-minus\pmÂ± 0.40 | 91.7 Â±plus-or-minus\pmÂ± 0.35 | 90.3 Â±plus-or-minus\pmÂ± 0.07 | 68.0 Â±plus-or-minus\pmÂ± 0.10 | 77.3 Â±plus-or-minus\pmÂ± 0.09 | 79.3 Â±plus-or-minus\pmÂ± 0.11 | 84.7  
DynaCor |  98.0 Â±plus-or-minus\pmÂ± 0.04 |  94.0 Â±plus-or-minus\pmÂ± 0.15 |  92.3 Â±plus-or-minus\pmÂ± 0.38 | 79.6 Â±plus-or-minus\pmÂ± 0.37 | 92.3 Â±plus-or-minus\pmÂ± 0.19 | 94.3 Â±plus-or-minus\pmÂ± 0.34 |  76.3 Â±plus-or-minus\pmÂ± 0.23 |  81.7 Â±plus-or-minus\pmÂ± 0.21 |  80.4 Â±plus-or-minus\pmÂ± 0.17 | 87.7  
Table 1:  Average F1 score (%) along with standard deviation across ten independent runs of DynaCor and baseline methods on CIFAR-10 and CIFAR-100. All methods except SIMIFEAT utilize the identical fixed image encoder from CLIP [[37](https://arxiv.org/html/2405.19902v1#bib.bib37)] and train only a subsequent MLP, while SIMIFEAT uses pre-trained CLIP as a feature extractor. The rightmost column averages the F1 scores across nine different settings. â€œAgg.â€, â€œWorstâ€, and â€œHumanâ€ correspond to the real-world human label noises [[53](https://arxiv.org/html/2405.19902v1#bib.bib53)]. The best results are in bold.  Dataset | CIFAR-10 | CIFAR-100 |   
---|---|---|---  
Noise type | Sym. | Asym. | Inst. | Agg. | Worst | Sym. | Asym. | Inst. | Human | Avg.  
Avg.Encoder | 94.1 Â±plus-or-minus\pmÂ± 0.14 | 85.4 Â±plus-or-minus\pmÂ± 0.19 | 88.5 Â±plus-or-minus\pmÂ± 0.20 | 63.6 Â±plus-or-minus\pmÂ± 0.72 | 87.6 Â±plus-or-minus\pmÂ± 0.18 |  92.5 Â±plus-or-minus\pmÂ± 0.34 | 75.2 Â±plus-or-minus\pmÂ± 0.36 | 76.0 Â±plus-or-minus\pmÂ± 0.49 |  78.8 Â±plus-or-minus\pmÂ± 0.18 | 82.4  
AUM | 75.4 Â±plus-or-minus\pmÂ± 0.22 | 46.4 Â±plus-or-minus\pmÂ± 0.30 | 57.7 Â±plus-or-minus\pmÂ± 0.03 | 16.7 Â±plus-or-minus\pmÂ± 0.01 | 57.8 Â±plus-or-minus\pmÂ± 0.04 | 75.8 Â±plus-or-minus\pmÂ± 0.21 | 46.7 Â±plus-or-minus\pmÂ± 0.32 | 57.8 Â±plus-or-minus\pmÂ± 0.10 | 58.0 Â±plus-or-minus\pmÂ± 0.21 | 54.7  
CL | 88.7 Â±plus-or-minus\pmÂ± 0.56 | 91.9 Â±plus-or-minus\pmÂ± 0.12 | 82.5 Â±plus-or-minus\pmÂ± 0.37 | 57.0 Â±plus-or-minus\pmÂ± 0.31 | 80.0 Â±plus-or-minus\pmÂ± 0.32 | 77.9 Â±plus-or-minus\pmÂ± 0.39 | 62.4 Â±plus-or-minus\pmÂ± 0.24 | 67.3 Â±plus-or-minus\pmÂ± 0.28 | 65.2 Â±plus-or-minus\pmÂ± 0.19 | 74.8  
CORES | 92.9 Â±plus-or-minus\pmÂ± 0.17 | 26.7 Â±plus-or-minus\pmÂ± 0.44 | 49.2 Â±plus-or-minus\pmÂ± 1.15 | 63.6 Â±plus-or-minus\pmÂ± 0.58 | 74.7 Â±plus-or-minus\pmÂ± 0.36 | 66.3 Â±plus-or-minus\pmÂ± 0.35 | 33.8 Â±plus-or-minus\pmÂ± 0.46 | 39.2 Â±plus-or-minus\pmÂ± 0.45 | 31.9 Â±plus-or-minus\pmÂ± 0.48 | 53.2  
SIMIFEAT-V |  94.6 Â±plus-or-minus\pmÂ± 0.06 | 84.7 Â±plus-or-minus\pmÂ± 0.17 | 83.7 Â±plus-or-minus\pmÂ± 0.08 | 69.4 Â±plus-or-minus\pmÂ± 0.17 | 88.3 Â±plus-or-minus\pmÂ± 0.08 | 88.0 Â±plus-or-minus\pmÂ± 0.09 | 70.3 Â±plus-or-minus\pmÂ± 0.14 | 77.8 Â±plus-or-minus\pmÂ± 0.10 | 76.2 Â±plus-or-minus\pmÂ± 0.14 | 81.4  
SIMIFEAT-R | 92.9 Â±plus-or-minus\pmÂ± 1.84 | 84.0 Â±plus-or-minus\pmÂ± 0.13 | 86.9 Â±plus-or-minus\pmÂ± 0.08 | 68.8 Â±plus-or-minus\pmÂ± 0.32 |  88.5 Â±plus-or-minus\pmÂ± 0.36 | 89.7 Â±plus-or-minus\pmÂ± 0.07 | 66.2 Â±plus-or-minus\pmÂ± 0.11 | 75.5 Â±plus-or-minus\pmÂ± 0.08 | 77.8 Â±plus-or-minus\pmÂ± 0.13 | 81.2  
DynaCor | 93.6 Â±plus-or-minus\pmÂ± 0.18 |  94.2 Â±plus-or-minus\pmÂ± 0.45 |  91.5 Â±plus-or-minus\pmÂ± 0.31 |  72.6 Â±plus-or-minus\pmÂ± 2.46 | 87.8 Â±plus-or-minus\pmÂ± 0.37 | 91.3 Â±plus-or-minus\pmÂ± 0.46 |  79.2 Â±plus-or-minus\pmÂ± 0.59 |  79.5 Â±plus-or-minus\pmÂ± 1.14 | 77.3 Â±plus-or-minus\pmÂ± 0.54 | 85.2  
Table 2:  Average F1 score (%) under identical settings to those in Table [1](https://arxiv.org/html/2405.19902v1#S5.T1 "Table 1 â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") except for the backbone model. All methods except SIMIFEAT utilize a randomly initialized Renset34 [[17](https://arxiv.org/html/2405.19902v1#bib.bib17)], while SIMIFEAT uses a pre-trained ResNet34 on ImageNet [[11](https://arxiv.org/html/2405.19902v1#bib.bib11)] as a feature extractor. 

###  5.1 Experiment setup

Datasets.  We evaluate the performance of DynaCor on benchmark datasets with different types of label noise, originating from diverse sources: (1) synthetic noise on CIFAR-10 and CIFAR-100 [[25](https://arxiv.org/html/2405.19902v1#bib.bib25)], (2) real-world human noise on CIFAR-10N and CIFAR-100N [[53](https://arxiv.org/html/2405.19902v1#bib.bib53)], and (3) systematic noise444In case of Clothing1M, systematic noise is induced by automatic annotation from the keywords present in the surrounding text of each image. on Clothing1M [[57](https://arxiv.org/html/2405.19902v1#bib.bib57)]. In the case of synthetic noise, following the previous experimental setup [[67](https://arxiv.org/html/2405.19902v1#bib.bib67)], we artificially introduce the noise by using different strategies with specific noise rates Î·ğœ‚\etaitalic_Î· as outlined below.

  * â€¢

Symmetric Noise (Sym., Î·=0.6ğœ‚0.6\eta=0.6italic_Î· = 0.6) randomly replaces the label with one of the other classes.

  * â€¢

Asymmetric Noise (Asym., Î·=0.3ğœ‚0.3\eta=0.3italic_Î· = 0.3) performs pairwise label flipping, where transition can only occur from a given class iğ‘–iitalic_i to the next class (iâ¢modeâ¢C)+1ğ‘–modeğ¶1(i\ \mathrm{mode}\ C)+1( italic_i roman_mode italic_C ) + 1.

  * â€¢

Instance-dependent Noise (Inst., Î·=0.4ğœ‚0.4\eta=0.4italic_Î· = 0.4) changes labels based on the transition probability calculated using instanceâ€™s corresponding features [[56](https://arxiv.org/html/2405.19902v1#bib.bib56)].




In the case of human noise, we choose two noise subtypes for CIFAR-10N (denoted by Agg. and Worst) and a single noise subtype for CIFAR-100N (denoted by Human). More details of the datasets are presented in Appendix A.1.

Baselines.  We compare DynaCor with various noisy label detection methods. All the methods except SIMIFEAT use training signals to identify incorrectly labeled instances.

  * â€¢

Avg.Encoder is a naive baseline that discriminates between clean and noisy labels by using a one-dimensional Gaussian mixture model [[68](https://arxiv.org/html/2405.19902v1#bib.bib68)] on the averaged training signals (i.e., logit difference) over the epochs.

  * â€¢

AUM [[36](https://arxiv.org/html/2405.19902v1#bib.bib36)] uses summation of training signals (i.e., logit difference) over the epochs and identifies correctly/incorrectly labeled instances based on a threshold.

  * â€¢

CL [[33](https://arxiv.org/html/2405.19902v1#bib.bib33)] uses a predicted probability of the given label (i.e., confidence) and filter out the instances with low confidence based on class-conditional thresholds.

  * â€¢

CORES [[7](https://arxiv.org/html/2405.19902v1#bib.bib7)] leverages a training loss for noisy label detection, progressively filtering out incorrectly labeled instances using its proposed sample sieve.

  * â€¢

SIMIFEAT [[67](https://arxiv.org/html/2405.19902v1#bib.bib67)] is a training-free approach that effectively detects noisy labels by utilizing Kğ¾Kitalic_K-nearest neighbors in the feature space of a pre-trained model.




Implementation details.  For our label corruption process, we use the corruption rate Î³=0.1ğ›¾0.1\gamma=0.1italic_Î³ = 0.1 as the default. To generate the training dynamics, we employ DNN classifiers: ResNet34 [[17](https://arxiv.org/html/2405.19902v1#bib.bib17)] and the pre-trained ViT-B/32-CLIP [[37](https://arxiv.org/html/2405.19902v1#bib.bib37)] with a multi-layer perceptron (MLP) of two hidden layers. To encode the training dynamics, we use a three-layered 1D-CNN architecture [[51](https://arxiv.org/html/2405.19902v1#bib.bib51)] as the dynamics encoder. The hyperparameter Î±ğ›¼\alphaitalic_Î± is selected as either 0.05 or 0.5. For more details about implementation, please refer to Appendix A.2.

###  5.2 Noisy label detection performance

We first evaluate DynaCor and the baseline methods for noisy label detection. Table [1](https://arxiv.org/html/2405.19902v1#S5.T1 "Table 1 â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") and Table [2](https://arxiv.org/html/2405.19902v1#S5.T2 "Table 2 â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") present their detection F1 scores for two classifiers, CLIP w/ MLP and ResNet34, across various noise types and rates. Notably, DynaCor achieves the best performance on average, i.e., +++3.0% in Table [1](https://arxiv.org/html/2405.19902v1#S5.T1 "Table 1 â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") and +++2.8% in Table [2](https://arxiv.org/html/2405.19902v1#S5.T2 "Table 2 â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"), demonstrating its robustness to various types of noisy conditions. On the other hand, the baseline methods relying on training signals (i.e., Avg.Encoder, AUM, CL, and CORES) show considerable variations in performance across different noise types. For example, in the case of CIFAR-10, Avg.Encoder and CORES perform well for symmetric noises, whereas they struggle with identifying asymmetric or instance noises. It is worth noting that asymmetric and instance noise are more complex than symmetric noise in that they can have a more detrimental impact on model performance [[34](https://arxiv.org/html/2405.19902v1#bib.bib34)]. These results strongly support the superiority of our DynaCor framework in handling a wide range of label noise variations.

###  5.3 Effectiveness of validation metric

Validation metric | CIFAR-10 | CIFAR-100  
---|---|---  
Inst. | Agg. | Inst. | Human  
Max epoch | 86.7 Â±plus-or-minus\pmÂ± 6.75 | 77.8 Â±plus-or-minus\pmÂ± 3.35 | 61.0 Â±plus-or-minus\pmÂ± 10.3 | 64.3 Â±plus-or-minus\pmÂ± 4.40  
DBI | 86.3 Â±plus-or-minus\pmÂ± 8.75 | 76.7 Â±plus-or-minus\pmÂ± 3.91 | 60.0 Â±plus-or-minus\pmÂ± 10.2 | 64.8 Â±plus-or-minus\pmÂ± 9.70  
Ours | 92.3 Â±plus-or-minus\pmÂ± 0.38 | 79.6 Â±plus-or-minus\pmÂ± 0.37 | 81.7 Â±plus-or-minus\pmÂ± 0.21 | 80.4 Â±plus-or-minus\pmÂ± 0.17  
Opt epoch | 92.6 Â±plus-or-minus\pmÂ± 0.40 | 80.40 Â±plus-or-minus\pmÂ± 0.44 | 81.8 Â±plus-or-minus\pmÂ± 0.08 | 80.5 Â±plus-or-minus\pmÂ± 0.18  
  
Table 3: F1 score (%) of our dynamics encoder over various validation metrics on CIFAR-10 and CIFAR-100 using CLIP w/ MLP as a classifier.

(a) Supervised setting

(b) Unsupervised setting: DynaCor.

Figure 2: F1 score (%) changes with respect to corruption rate (Î³)ğ›¾(\gamma)( italic_Î³ ) on CIFAR10 in supervised and unsupervised settings using CLIP w/ MLP (Left) and ResNet34 (Right) as classifiers. 

To demonstrate the effectiveness of the proposed validation metric (Sec.[4.4.3](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS3 "4.4.3 Validation metric â€£ 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")), we compare the detection performance of our dynamics encoder by employing our proposed metric and alternative criteria as stopping conditions during the training. Max epoch signifies the training over the maximum number of epochs. Davies-Bouldin Index (DBI) [[10](https://arxiv.org/html/2405.19902v1#bib.bib10)] assesses the quality of clustering results by calculating the ratio of intra-cluster distances to inter-cluster separations. A lower DBI value implies more compact and well-separated clusters, i.e., better clustering quality. In addition, Opt epoch selects the optimal training epoch that achieves the best detection results, providing the upper bound of detection performance.

In Table [3](https://arxiv.org/html/2405.19902v1#S5.T3 "Table 3 â€£ 5.3 Effectiveness of validation metric â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"), our performance is close to the optimal case across various noise types and datasets, whereas Max epoch and DBI fail to stop the training process at a proper epoch on CIFAR-100. In conclusion, using the proper validation metric is critical for achieving competitive detection performance, particularly in the scenario where ground-truth annotations are not available for validation.

###  5.4 Quantitative analyses

The effect of corruption rate.  We analyze the effect of increasing the corruption rate, which in turn amplifies the overall noise level.555The overall noise rate is formulated as Î·oâ¢vâ¢eâ¢r=Î·+Î³â‹…Î·Î³1+Î³subscriptğœ‚ğ‘œğ‘£ğ‘’ğ‘Ÿğœ‚â‹…ğ›¾subscriptğœ‚ğ›¾1ğ›¾\eta_{over}=\frac{\eta+\gamma\cdot\eta_{\gamma}}{1+\gamma}italic_Î· start_POSTSUBSCRIPT italic_o italic_v italic_e italic_r end_POSTSUBSCRIPT = divide start_ARG italic_Î· + italic_Î³ â‹… italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT end_ARG start_ARG 1 + italic_Î³ end_ARG. For thorough analyses, we conduct a controlled experiment within a supervised framework using classification,666See Appendix B.1 for the details. assuming the availability of ground-truth annotations that indicate each instance as being correctly or incorrectly labeled. We then compare these results, generally regarded as the performance upper bound for unsupervised methods, with those obtained by an unsupervised approach. We focus on assessing the ability of our proposed unsupervised learning model, i.e., DynaCor, to discriminate training dynamics and how this discrimination is affected by increasing the overall noise level through corruption.

As shown in Figure [2](https://arxiv.org/html/2405.19902v1#S5.F2 "Figure 2 â€£ 5.3 Effectiveness of validation metric â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"), the detection F1 scores achieved by DynaCor (Figure [2(b)](https://arxiv.org/html/2405.19902v1#S5.F2.sf2 "Figure 2\(b\) â€£ Figure 2 â€£ 5.3 Effectiveness of validation metric â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")) approaches those of supervised learning (Figure [2(a)](https://arxiv.org/html/2405.19902v1#S5.F2.sf1 "Figure 2\(a\) â€£ Figure 2 â€£ 5.3 Effectiveness of validation metric â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")), demonstrating the effectiveness of training dynamics. This proximity is especially notable when utilizing a powerful image encoder, i.e., CLIP, which makes the training dynamics less susceptible to changes in the corruption rate. In contrast, the training dynamics from ResNet34 are more affected by increased corruption rate. Surprisingly, in the case of â€œInst.â€ type label noise, the training dynamics from the CLIP w/ MLP classifier become even more distinguishable as the corruption rate increases to 0.5. It shows that a higher noise rate in the training dataset can enhance the discernibility of the training dynamics. We hypothesize that the symmetric noise introduced through our label corruption process may reduce the overall difficulty of the detection task. This is consistent with the assertion in Sec. [4.4.2](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS2 "4.4.2 Learning discriminative patterns in dynamics â€£ 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") that the symmetric noise is relatively straightforward to identify and, in turn, contributes to improving the performance of noisy label detection.

â„’câ¢lâ¢uâ¢sâ¢tâ¢eâ¢rsubscriptâ„’ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿ\mathcal{L}_{cluster}caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_u italic_s italic_t italic_e italic_r end_POSTSUBSCRIPT | â„’aâ¢lâ¢iâ¢gâ¢nsubscriptâ„’ğ‘ğ‘™ğ‘–ğ‘”ğ‘›\mathcal{L}_{align}caligraphic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT | Asym. | Inst. | Agg.  
---|---|---|---|---  
|  | 93.8 Â±plus-or-minus\pmÂ± 0.17 | 91.8 Â±plus-or-minus\pmÂ± 0.39 | 78.8 Â±plus-or-minus\pmÂ± 0.37  
âœ“âœ“\checkmarkâœ“ |  | 93.2 Â±plus-or-minus\pmÂ± 0.11 |  92.7 Â±plus-or-minus\pmÂ± 0.36 | 76.8 Â±plus-or-minus\pmÂ± 0.83  
âœ“âœ“\checkmarkâœ“ | âœ“âœ“\checkmarkâœ“ |  94.0 Â±plus-or-minus\pmÂ± 0.15 | 92.3 Â±plus-or-minus\pmÂ± 0.38 |  79.6 Â±plus-or-minus\pmÂ± 0.37  
  
Table 4: F1 score (%) of DynaCor that ablates the clustering and alignment loss on CIFAR10 using CLIP w/ MLP as a classifier. The first row reports the detection performance with a randomly initialized dynamics encoder.

The effect of two losses.  We examine the effect of the clustering and alignment losses within our DynaCor framework. In Table [4](https://arxiv.org/html/2405.19902v1#S5.T4 "Table 4 â€£ 5.4 Quantitative analyses â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"), both losses enhance detection performance. We also observe that the alignment loss effectively addresses the high imbalance between clean and noisy instances, particularly in scenarios with a low noise rate (e.g., â€œAgg.â€ on CIFAR-10). Given that DynaCor intentionally increases the noise rate by augmenting instances with corrupted labels, its benefits become more pronounced when dealing with datasets featuring a small original noise rate. In such cases, the alignment loss is crucial in stabilizing the clustering process by aligning the distinct distributions of original and corrupted instances.

###  5.5 Compatibility analyses with robust learning 

(a) Classification accuracy (%) of robust learning

(b) Noisy label detection F1 score (%)

Figure 3: Compatibility analysis of Dividemix with DynaCor on CIFAR100 over â€œAsym.â€ and â€œInst.â€ with respect to noise rate

We investigate the compatibility and synergistic effects of integrating our framework with various robust learning techniques: a semi-supervised approach (Dividemix [[28](https://arxiv.org/html/2405.19902v1#bib.bib28)]), loss functions (GCE [[65](https://arxiv.org/html/2405.19902v1#bib.bib65)] and SCE [[50](https://arxiv.org/html/2405.19902v1#bib.bib50)]), and a regularization method (ELR [[31](https://arxiv.org/html/2405.19902v1#bib.bib31)]). Detailed analyses of incorporating the loss functions and regularization technique on the Clothing1M dataset are provided in Appendix D.

For the semi-supervised approach, we select Dividemix [[28](https://arxiv.org/html/2405.19902v1#bib.bib28)] that iteratively detects incorrectly labeled instances and treats them as unlabeled instances. We construct integrated models of Dividemix and DynaCor through two distinct approaches: (1) DDyna-L is leveraging Dividemix to obtain the training dynamics of both original and corrupted datasets within our framework, and (2) DDyna-S is substituting the original detection method in Dividemix, i.e., GMM, with DynaCor. For the base architecture, we employ an 18-layer PreAct ResNet [[18](https://arxiv.org/html/2405.19902v1#bib.bib18)], adhering to its default optimization settings and hyperparameters, as specified in the original paper [[28](https://arxiv.org/html/2405.19902v1#bib.bib28)].

Classification accuracy.  We explore the impact of our framework on the classifierâ€™s accuracy, specifically introducing a corrupted dataset (DDyna-L) and supplanting the existing noise detection method (DDyna-S). Figure [3(a)](https://arxiv.org/html/2405.19902v1#S5.F3.sf1 "Figure 3\(a\) â€£ Figure 3 â€£ 5.5 Compatibility analyses with robust learning â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") demonstrates that both enhance classification performance. In essence, results obtained with DDyna-L demonstrate that instances with symmetric label noise introduced through our corruption process prove beneficial for noise robust learning, especially in scenarios featuring a low noise rate in the original dataset, pointed out as a challenging setting for Dividemix [[53](https://arxiv.org/html/2405.19902v1#bib.bib53)].

Detection F1 score.  To report the noisy label detection performance within robust learning framework, i.e., Dividemix and DDyna-S, we measure F1 score at every epoch and report the value when test classification accuracy is at its highest. Note that they leverage a clean test dataset to identify the optimal detection point; on the contrary, the noisy detection method (DDyna-L) operates without access to clean data, instead employing the procedure for model validation on the noisy dataset itself (Sec. [4.4.3](https://arxiv.org/html/2405.19902v1#S4.SS4.SSS3 "4.4.3 Validation metric â€£ 4.4 Noisy label detection via dynamics clustering â€£ 4 Methodology â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")), presenting a more challenging task. Figure [3(b)](https://arxiv.org/html/2405.19902v1#S5.F3.sf2 "Figure 3\(b\) â€£ Figure 3 â€£ 5.5 Compatibility analyses with robust learning â€£ 5 Experiments â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") indicates that DDyna-S and DDyna-L further improves the detection F1 score of Dividemix, indicating the great compatibility of DynaCor with existing semi-supervised noise robust learning. In scenarios involving â€œInst.â€ label noise, DDyna-L exhibits compelling synergistic effects across a wide range of noise rates.

##  6 Conclusion

This paper proposes a new DynaCor framework that distinguishes incorrectly labeled instances from correctly labeled ones via clustering of their training dynamics. DynaCor first introduces a label corruption strategy that augments the original dataset with intentionally corrupted labels, enabling indirect simulation of the modelâ€™s behavior on noisy labels. Subsequently, DynaCor learns to induce two clearly distinguishable clusters for clean and noisy instances by enhancing the cluster cohesion and alignment between the original and corrupted dataset. Furthermore, DynaCor adopts a simple yet effective validation metric to indirectly estimate its detection performance in the absence of annotations of clean and noisy labels. Our comprehensive experiments on real-world datasets demonstrate the detection efficacy of DynaCor, its remarkable robustness to various noise types and noise rates, and great compatibility with existing approaches to noise robust learning.

##  7 Acknowledgements

This work was supported by the IITP grant funded by the MSIT (No.2018-0-00584, 2019-0-01906, 2020-0-01361), the NRF grant funded by the MSIT (No.2020R1A2B5B03097210, RS-2023-00217286), and the Digital Innovation Hub project supervised by the Daegu Digital Innovation Promotion Agency (DIP) grant funded by the Korea government (MSIT and Daegu Metropolitan City) in 2024 (No. DBSD1-07).

## References

  * Arpit et al. [2017] Devansh Arpit, StanisÅ‚aw JastrzÄ™bski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al.  A closer look at memorization in deep networks.  In _International conference on machine learning_ , pages 233â€“242. PMLR, 2017. 
  * Bekker and Goldberger [2016] Alan Joseph Bekker and Jacob Goldberger.  Training deep neural-networks based on unreliable labels.  In _2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)_ , pages 2682â€“2686. IEEE, 2016. 
  * Berthelot et al. [2019] David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raffel.  Mixmatch: A holistic approach to semi-supervised learning.  _Advances in neural information processing systems_ , 32, 2019. 
  * Chen et al. [2023] Wenkai Chen, Chuang Zhu, and Mengting Li.  Sample prior guided robust model learning to suppress noisy labels.  In _Joint European Conference on Machine Learning and Knowledge Discovery in Databases_ , pages 3â€“19. Springer, 2023. 
  * Chen and Gupta [2015] Xinlei Chen and Abhinav Gupta.  Webly supervised learning of convolutional networks.  In _Proceedings of the IEEE international conference on computer vision_ , pages 1431â€“1439, 2015. 
  * Cheng et al. [2022] De Cheng, Yixiong Ning, Nannan Wang, Xinbo Gao, Heng Yang, Yuxuan Du, Bo Han, and Tongliang Liu.  Class-dependent label-noise learning with cycle-consistency regularization.  _Advances in Neural Information Processing Systems_ , 35:11104â€“11116, 2022. 
  * Cheng et al. [2020a] Hao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu.  Learning with instance-dependent label noise: A sample sieve approach.  _arXiv preprint arXiv:2010.02347_ , 2020a. 
  * Cheng et al. [2021] Hao Cheng, Zhaowei Zhu, Xing Sun, and Yang Liu.  Mitigating memorization of noisy labels via regularization between representations.  _arXiv preprint arXiv:2110.09022_ , 2021. 
  * Cheng et al. [2020b] Lele Cheng, Xiangzeng Zhou, Liming Zhao, Dangwei Li, Hong Shang, Yun Zheng, Pan Pan, and Yinghui Xu.  Weakly supervised learning with side information for noisy labeled images.  In _Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part XXX 16_ , pages 306â€“321. Springer, 2020b. 
  * Davies and Bouldin [1979] David L Davies and Donald W Bouldin.  A cluster separation measure.  _IEEE transactions on pattern analysis and machine intelligence_ , (2):224â€“227, 1979. 
  * Deng et al. [2009] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.  Imagenet: A large-scale hierarchical image database.  In _2009 IEEE conference on computer vision and pattern recognition_ , pages 248â€“255. Ieee, 2009. 
  * Forouzesh and Thiran [2023] Mahsa Forouzesh and Patrick Thiran.  Differences between hard and noisy-labeled samples: An empirical study.  _arXiv preprint arXiv:2307.10718_ , 2023. 
  * Goldberger and Ben-Reuven [2016] Jacob Goldberger and Ehud Ben-Reuven.  Training deep neural-networks using a noise adaptation layer.  In _International conference on learning representations_ , 2016. 
  * Gui et al. [2021] Xian-Jin Gui, Wei Wang, and Zhang-Hao Tian.  Towards understanding deep learning from noisy labels with small-loss criterion.  _arXiv preprint arXiv:2106.09291_ , 2021. 
  * Han et al. [2018] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama.  Co-teaching: Robust training of deep neural networks with extremely noisy labels.  _Advances in neural information processing systems_ , 31, 2018. 
  * Han et al. [2019] Jiangfan Han, Ping Luo, and Xiaogang Wang.  Deep self-learning from noisy labels.  In _Proceedings of the IEEE/CVF international conference on computer vision_ , pages 5138â€“5147, 2019. 
  * He et al. [2016a] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.  Deep residual learning for image recognition.  In _Proceedings of the IEEE conference on computer vision and pattern recognition_ , pages 770â€“778, 2016a. 
  * He et al. [2016b] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.  Identity mappings in deep residual networks.  In _Computer Visionâ€“ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11â€“14, 2016, Proceedings, Part IV 14_ , pages 630â€“645. Springer, 2016b. 
  * Huang et al. [2019] Jinchi Huang, Lie Qu, Rongfei Jia, and Binqiang Zhao.  O2u-net: A simple noisy label detection approach for deep neural networks.  In _Proceedings of the IEEE/CVF international conference on computer vision_ , pages 3326â€“3334, 2019. 
  * Jiang et al. [2018] Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei.  Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels.  In _International conference on machine learning_ , pages 2304â€“2313. PMLR, 2018. 
  * Jindal et al. [2016] Ishan Jindal, Matthew Nokleby, and Xuewen Chen.  Learning deep networks from noisy labels with dropout regularization.  In _2016 IEEE 16th International Conference on Data Mining (ICDM)_ , pages 967â€“972. IEEE, 2016. 
  * Kim et al. [2021a] Taehyeon Kim, Jongwoo Ko, JinHwan Choi, Se-Young Yun, et al.  Fine samples for learning with noisy labels.  _Advances in Neural Information Processing Systems_ , 34:24137â€“24149, 2021a. 
  * Kim et al. [2021b] Taehyeon Kim, Jaehoon Oh, NakYil Kim, Sangwook Cho, and Se-Young Yun.  Comparing kullback-leibler divergence and mean squared error loss in knowledge distillation.  _arXiv preprint arXiv:2105.08919_ , 2021b. 
  * Kingma and Ba [2014] Diederik P Kingma and Jimmy Ba.  Adam: A method for stochastic optimization.  _arXiv preprint arXiv:1412.6980_ , 2014. 
  * Krizhevsky et al. [2009] Alex Krizhevsky, Geoffrey Hinton, et al.  Learning multiple layers of features from tiny images.  2009\. 
  * Krizhevsky et al. [2012] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.  Imagenet classification with deep convolutional neural networks.  _Advances in neural information processing systems_ , 25, 2012. 
  * Lee et al. [2018] Kuang-Huei Lee, Xiaodong He, Lei Zhang, and Linjun Yang.  Cleannet: Transfer learning for scalable image classifier training with label noise.  In _Proceedings of the IEEE conference on computer vision and pattern recognition_ , pages 5447â€“5456, 2018. 
  * Li et al. [2020] Junnan Li, Richard Socher, and Steven CH Hoi.  Dividemix: Learning with noisy labels as semi-supervised learning.  _arXiv preprint arXiv:2002.07394_ , 2020. 
  * Li et al. [2017] Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool.  Webvision database: Visual learning and understanding from web data.  _arXiv preprint arXiv:1708.02862_ , 2017. 
  * Lipton et al. [2014] Zachary C Lipton, Charles Elkan, and Balakrishnan Naryanaswamy.  Optimal thresholding of classifiers to maximize f1 measure.  In _Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part II 14_ , pages 225â€“239. Springer, 2014. 
  * Liu et al. [2020] Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda.  Early-learning regularization prevents memorization of noisy labels.  _Advances in neural information processing systems_ , 33:20331â€“20342, 2020. 
  * Lukasik et al. [2020] Michal Lukasik, Srinadh Bhojanapalli, Aditya Menon, and Sanjiv Kumar.  Does label smoothing mitigate label noise?  In _International Conference on Machine Learning_ , pages 6448â€“6458. PMLR, 2020. 
  * Northcutt et al. [2021] Curtis Northcutt, Lu Jiang, and Isaac Chuang.  Confident learning: Estimating uncertainty in dataset labels.  _Journal of Artificial Intelligence Research_ , 70:1373â€“1411, 2021. 
  * Oyen et al. [2022] Diane Oyen, Michal Kucer, Nicolas Hengartner, and Har Simrat Singh.  Robustness to label noise depends on the shape of the noise distribution.  _Advances in Neural Information Processing Systems_ , 35:35645â€“35656, 2022. 
  * Peterson et al. [2019] Joshua C Peterson, Ruairidh M Battleday, Thomas L Griffiths, and Olga Russakovsky.  Human uncertainty makes classification more robust.  In _Proceedings of the IEEE/CVF International Conference on Computer Vision_ , pages 9617â€“9626, 2019. 
  * Pleiss et al. [2020] Geoff Pleiss, Tianyi Zhang, Ethan Elenberg, and Kilian Q Weinberger.  Identifying mislabeled data using the area under the margin ranking.  _Advances in Neural Information Processing Systems_ , 33:17044â€“17056, 2020. 
  * Radford et al. [2021] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.  Learning transferable visual models from natural language supervision.  In _International conference on machine learning_ , pages 8748â€“8763. PMLR, 2021. 
  * Ren et al. [2018] Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun.  Learning to reweight examples for robust deep learning.  In _International conference on machine learning_ , pages 4334â€“4343. PMLR, 2018. 
  * Rousseeuw [1987] Peter J Rousseeuw.  Silhouettes: a graphical aid to the interpretation and validation of cluster analysis.  _Journal of computational and applied mathematics_ , 20:53â€“65, 1987. 
  * Shu et al. [2019] Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng.  Meta-weight-net: Learning an explicit mapping for sample weighting.  _Advances in neural information processing systems_ , 32, 2019. 
  * Song et al. [2019] Hwanjun Song, Minseok Kim, and Jae-Gil Lee.  Selfie: Refurbishing unclean samples for robust deep learning.  In _International Conference on Machine Learning_ , pages 5907â€“5915. PMLR, 2019. 
  * Sukhbaatar et al. [2014] Sainbayar Sukhbaatar, Joan Bruna, Manohar Paluri, Lubomir Bourdev, and Rob Fergus.  Training convolutional networks with noisy labels.  _arXiv preprint arXiv:1406.2080_ , 2014. 
  * Sun et al. [2020] Zeren Sun, Xian-Sheng Hua, Yazhou Yao, Xiu-Shen Wei, Guosheng Hu, and Jian Zhang.  Crssc: salvage reusable samples from noisy data for robust learning.  In _Proceedings of the 28th ACM International Conference on Multimedia_ , pages 92â€“101, 2020. 
  * Swayamdipta et al. [2020] Swabha Swayamdipta, Roy Schwartz, Nicholas Lourie, Yizhong Wang, Hannaneh Hajishirzi, Noah A Smith, and Yejin Choi.  Dataset cartography: Mapping and diagnosing datasets with training dynamics.  In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_ , pages 9275â€“9293, 2020. 
  * Torkzadehmahani et al. [2022] Reihaneh Torkzadehmahani, Reza Nasirigerdeh, Daniel Rueckert, and Georgios Kaissis.  Label noise-robust learning using a confidence-based sieving strategy.  _arXiv preprint arXiv:2210.05330_ , 2022. 
  * Van der Maaten and Hinton [2008] Laurens Van der Maaten and Geoffrey Hinton.  Visualizing data using t-sne.  _Journal of machine learning research_ , 9(11), 2008. 
  * Wang et al. [2022a] Haonan Wang, Wei Huang, Ziwei Wu, Hanghang Tong, Andrew J Margenot, and Jingrui He.  Deep active learning by leveraging training dynamics.  _Advances in Neural Information Processing Systems_ , 35:25171â€“25184, 2022a. 
  * Wang et al. [2022b] Haobo Wang, Ruixuan Xiao, Yiwen Dong, Lei Feng, and Junbo Zhao.  Promix: combating label noise via maximizing clean sample utility.  _arXiv preprint arXiv:2207.10276_ , 2022b. 
  * Wang et al. [2021] Jingkang Wang, Hongyi Guo, Zhaowei Zhu, and Yang Liu.  Policy learning using weak supervision.  _Advances in Neural Information Processing Systems_ , 34:19960â€“19973, 2021. 
  * Wang et al. [2019] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey.  Symmetric cross entropy for robust learning with noisy labels.  In _Proceedings of the IEEE/CVF international conference on computer vision_ , pages 322â€“330, 2019. 
  * Wang et al. [2017] Zhiguang Wang, Weizhong Yan, and Tim Oates.  Time series classification from scratch with deep neural networks: A strong baseline.  In _2017 International joint conference on neural networks (IJCNN)_ , pages 1578â€“1585. IEEE, 2017. 
  * Wei et al. [2021a] Hongxin Wei, Lue Tao, Renchunzi Xie, and Bo An.  Open-set label noise can improve robustness against inherent label noise.  _Advances in Neural Information Processing Systems_ , 34:7978â€“7992, 2021a. 
  * Wei et al. [2021b] Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang Liu.  Learning with noisy labels revisited: A study using real-world human annotations.  _arXiv preprint arXiv:2110.12088_ , 2021b. 
  * Wei et al. [2022] Qi Wei, Haoliang Sun, Xiankai Lu, and Yilong Yin.  Self-filtering: A noise-aware sample selection for label noise with confidence penalization.  In _European Conference on Computer Vision_ , pages 516â€“532. Springer, 2022. 
  * Xia et al. [2020a] Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge, and Yi Chang.  Robust early-learning: Hindering the memorization of noisy labels.  In _International conference on learning representations_ , 2020a. 
  * Xia et al. [2020b] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama.  Part-dependent label noise: Towards instance-dependent label noise.  _Advances in Neural Information Processing Systems_ , 33:7597â€“7610, 2020b. 
  * Xiao et al. [2015] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang.  Learning from massive noisy labeled data for image classification.  In _Proceedings of the IEEE conference on computer vision and pattern recognition_ , pages 2691â€“2699, 2015. 
  * Xie et al. [2016] Junyuan Xie, Ross Girshick, and Ali Farhadi.  Unsupervised deep embedding for clustering analysis.  In _International conference on machine learning_ , pages 478â€“487. PMLR, 2016. 
  * Yao et al. [2018] Jiangchao Yao, Jiajie Wang, Ivor W Tsang, Ya Zhang, Jun Sun, Chengqi Zhang, and Rui Zhang.  Deep learning from noisy image labels with quality embedding.  _IEEE Transactions on Image Processing_ , 28(4):1909â€“1922, 2018. 
  * Yu et al. [2019] Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama.  How does disagreement help generalization against label corruption?  In _International Conference on Machine Learning_ , pages 7164â€“7173. PMLR, 2019. 
  * Zeiler [2012] Matthew D Zeiler.  Adadelta: an adaptive learning rate method.  _arXiv preprint arXiv:1212.5701_ , 2012. 
  * Zhang et al. [2021] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.  Understanding deep learning (still) requires rethinking generalization.  _Communications of the ACM_ , 64(3):107â€“115, 2021. 
  * Zhang et al. [2017] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz.  mixup: Beyond empirical risk minimization.  _arXiv preprint arXiv:1710.09412_ , 2017. 
  * Zhang and Sabuncu [2018] Zhilu Zhang and Mert Sabuncu.  Generalized cross entropy loss for training deep neural networks with noisy labels.  _Advances in neural information processing systems_ , 31, 2018. 
  * Zhang et al. [2020] Zizhao Zhang, Han Zhang, Sercan O Arik, Honglak Lee, and Tomas Pfister.  Distilling effective supervision from severe label noise.  In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_ , pages 9294â€“9303, 2020. 
  * Zhou et al. [2020] Tianyi Zhou, Shengjie Wang, and Jeffrey Bilmes.  Curriculum learning by dynamic instance hardness.  _Advances in Neural Information Processing Systems_ , 33:8602â€“8613, 2020. 
  * Zhu et al. [2022] Zhaowei Zhu, Zihao Dong, and Yang Liu.  Detecting corrupted labels without training a model to predict.  In _International conference on machine learning_ , pages 27412â€“27427. PMLR, 2022. 
  * Zoran and Weiss [2011] Daniel Zoran and Yair Weiss.  From learning models of natural image patches to whole image restoration.  In _2011 international conference on computer vision_ , pages 479â€“486. IEEE, 2011. 



## Supplementary Material: â€œLearning Discriminative Dynamics with Label Corruption for Noisy Label Detectionâ€

##  Appendix A Experiment Setup

###  A.1 Datasets

Synthetic noise: instance-dependent label noise.  We detail the process of generating instance-dependent label noise [[56](https://arxiv.org/html/2405.19902v1#bib.bib56)], which is the synthetic type label noise utilized in our experiments. The key idea is that the probability of an instance being incorrectly labeled to other classes is calculated based on both the input feature and its label, using randomly generated feature projection matrices with respect to each class. The procedure is provided in Algorithm [1](https://arxiv.org/html/2405.19902v1#alg1 "Algorithm 1 â€£ A.1 Datasets â€£ Appendix A Experiment Setup â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection").

Algorithm 1 Instance-Dependent Label Noise Synthesis

Input: Clean dataset D={(ğ±n,yn)}n=1Nğ·subscriptsuperscriptsubscriptğ±ğ‘›subscriptğ‘¦ğ‘›ğ‘ğ‘›1D=\\{(\mathbf{x}_{n},y_{n})\\}^{N}_{n=1}italic_D = { ( bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) } start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT, ğ±nâˆˆâ„dğ±subscriptğ±ğ‘›superscriptâ„subscriptğ‘‘ğ±\mathbf{x}_{n}\in\mathbb{R}^{d_{\mathbf{x}}}bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, Noise rate Î·ğœ‚\etaitalic_Î·, Number of classes Cğ¶Citalic_C   
Output: Noisily labeled dataset D~={(ğ±n,y~n)}n=1N~ğ·subscriptsuperscriptsubscriptğ±ğ‘›subscript~ğ‘¦ğ‘›ğ‘ğ‘›1\tilde{D}=\\{(\mathbf{x}_{n},\tilde{y}_{n})\\}^{N}_{n=1}over~ start_ARG italic_D end_ARG = { ( bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) } start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT

1: Sample Cğ¶Citalic_C feature projection matrices {ğ–1subscriptğ–1\mathbf{W}_{1}bold_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, â€¦,ğ–Csubscriptğ–ğ¶\mathbf{W}_{C}bold_W start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT} from a standard normal distribution ğ’©â¢(0,1)ğ’©01\mathcal{N}(0,1)caligraphic_N ( 0 , 1 ), with each ğ–câˆˆâ„dğ±Ã—Csubscriptğ–ğ‘superscriptâ„subscriptğ‘‘ğ±ğ¶\mathbf{W}_{c}\in\mathbb{R}^{d_{\mathbf{x}}\times C}bold_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT Ã— italic_C end_POSTSUPERSCRIPT. 

2: for n=1,â€¦,Nğ‘›1â€¦ğ‘n=1,\ldots,Nitalic_n = 1 , â€¦ , italic_N do

3: Sample qâˆˆâ„ğ‘â„q\in\mathbb{R}italic_q âˆˆ blackboard_R from a truncated normal distribution ğ’©â¢(Î·,0.12)ğ’©ğœ‚superscript0.12\mathcal{N}(\eta,0.1^{2})caligraphic_N ( italic_Î· , 0.1 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) within the interval [0,1]. 

4: Compute probability vector by p=ğ±nâ¢ğ–ynâˆˆâ„Cğ‘subscriptğ±ğ‘›subscriptğ–subscriptğ‘¦ğ‘›superscriptâ„ğ¶p=\mathbf{x}_{n}\mathbf{W}_{y_{n}}\in\mathbb{R}^{C}italic_p = bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT bold_W start_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT. 

5: Set the probability of the true class to be negative infinity pyn=âˆ’âˆsubscriptğ‘subscriptğ‘¦ğ‘›p_{y_{n}}=-\inftyitalic_p start_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT = - âˆ. 

6: Adjust p=qÃ—Softmaxâ¢(p)ğ‘ğ‘Softmaxğ‘p=q\times\mathrm{Softmax}(p)italic_p = italic_q Ã— roman_Softmax ( italic_p ) and set pyn=1âˆ’qsubscriptğ‘subscriptğ‘¦ğ‘›1ğ‘p_{y_{n}}=1-qitalic_p start_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT = 1 - italic_q. 

7: Sample corrupted label y~nsubscript~ğ‘¦ğ‘›\tilde{y}_{n}over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT from Cğ¶Citalic_C classes according to the modified probability distribution pğ‘pitalic_p. 

8: end for

Clothing1M [[57](https://arxiv.org/html/2405.19902v1#bib.bib57)].  To assess DynaCorâ€™s performance with systematic type label noise, we use a real-world dataset Clothing1M, which consists of clothing images across 14 classes777T-shirt, Shirt, Knitwear, Chiffon, Sweater, Hoodie, Windbreaker, Jacket, Down Coat, Suit, Shawl, Dress, Vest, and Underwear collected from online shopping websites. It comprises one million images with inherent noisy labels induced by automated annotations derived from keywords in the text surrounding each image. It also provides 50K, 14K, and 10K instances verified as clean for training, validation, and testing purposes. Adhering to the previous experimental setup [[22](https://arxiv.org/html/2405.19902v1#bib.bib22)], for training, we utilize randomly sampled 120K instances from the 1M noisy dataset while ensuring each class is balanced. To evaluate classification performance, we use the 10K clean test set.

###  A.2 Reproducibility

For reproducibility, we provide detailed hyperparameters for (1) classifiers used to generate training dynamics or to learn robust models and (2) dynamics encoder to learn discriminative representations of the training dynamics.

Classifier.  Table [5](https://arxiv.org/html/2405.19902v1#A1.T5 "Table 5 â€£ A.2 Reproducibility â€£ Appendix A Experiment Setup â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") shows details of the datasets, models, and training parameters used to generate training dynamics or to learn robust models in each section of this paper. Optimizer and momentum are fixed as SGD and 0.9, respectively. In the case of CLIP with MLP, we obtain input features using a fixed image encoder from CLIP and train only MLP, which consists of two fully connected layers of 512 units with ReLUs [[26](https://arxiv.org/html/2405.19902v1#bib.bib26)]. Resnet50 is pre-trained on ImageNet [[11](https://arxiv.org/html/2405.19902v1#bib.bib11)] and is fine-tuned on Clothing1M. We follow the experimental setups described in the reference papers.

Dataset | CIFAR-10/CIFAR-100 | Clothing1M  
---|---|---  
Section | 5.2 to 5.4 | 5.5 | Appendix [D](https://arxiv.org/html/2405.19902v1#A4 "Appendix D Compatibility analysis with robust learning on Clothing 1M dataset â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")  
Model |  CLIP [[37](https://arxiv.org/html/2405.19902v1#bib.bib37)] w/ MLP |  Resnet34 [[17](https://arxiv.org/html/2405.19902v1#bib.bib17), [53](https://arxiv.org/html/2405.19902v1#bib.bib53)] |  PreAct- Resnet18 [[18](https://arxiv.org/html/2405.19902v1#bib.bib18), [28](https://arxiv.org/html/2405.19902v1#bib.bib28)] |  Resnet50 [[17](https://arxiv.org/html/2405.19902v1#bib.bib17), [22](https://arxiv.org/html/2405.19902v1#bib.bib22)]  
Learning rate | 0.1 | 0.1 | 0.02 | 0.002  
Weight decay | 5Ã—10âˆ’45superscript1045\times 10^{-4}5 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT | 5Ã—10âˆ’45superscript1045\times 10^{-4}5 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT | 5Ã—10âˆ’45superscript1045\times 10^{-4}5 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT | 0.001  
LR scheduler | Cosine | Multi-step | Multi-step | Multi-step  
Batch size | 128 | 128 | 128 | 64  
Epochs | 30 | 100 | 300 | 10  
Î±ğ›¼\alphaitalic_Î± | 0.5 | 0.05 | 0.05 | 0.5  
  
Table 5: Detailed hyperparameters used in the experiments for the classifiers.

Dynamics encoder.  For the dynamics encoder in DynaCor, we use a 1D Convolutional Neural Network (1D-CNN). It consists of three convolutional layers, each incorporating rectified linear units (ReLUs) [[26](https://arxiv.org/html/2405.19902v1#bib.bib26)], followed by a linear layer with 512 output units. For optimization, we use Adam [[24](https://arxiv.org/html/2405.19902v1#bib.bib24)] with a learning rate 1Ã—10âˆ’51superscript1051\times 10^{-5}1 Ã— 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT and a weight decay 5Ã—10âˆ’45superscript1045\times 10^{-4}5 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT without implementing a learning rate scheduler. The model is trained for 10 epochs with a batch size of 1024.

##  Appendix B Analyses of Training Dynamics

To assess the distinguishability of the inherent patterns manifested in the training dynamics, we conduct a controlled experiment using classification within a supervised learning framework. This is predicated on the assumption that ground-truth annotations are available, explicitly specifying each instance as being correctly or incorrectly labeled.

We first provide preliminaries for analyses (Sec. [B.1](https://arxiv.org/html/2405.19902v1#A2.SS1 "B.1 Preliminaries â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")). Then, we demonstrate the efficacy of capturing temporal patterns in training dynamics versus summarizing these dynamics into a single scalar value (Sec. [B.2](https://arxiv.org/html/2405.19902v1#A2.SS2 "B.2 Temporal patterns in training dynamics â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")) on various training signals. Lastly, we evaluate which training signals exhibit more distinctive patterns (Sec. [B.3](https://arxiv.org/html/2405.19902v1#A2.SS3 "B.3 Comparison of various training signals â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")).

###  B.1 Preliminaries

Training signals.  Table [6](https://arxiv.org/html/2405.19902v1#A2.T6 "Table 6 â€£ B.1 Preliminaries â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") summarizes various training signals introduced in the literature. Given an instance (ğ±,y)ğ±ğ‘¦(\mathbf{x},y)( bold_x , italic_y ) and a classifier fğ‘“fitalic_f, let fâ¢(ğ±)âˆˆâ„Cğ‘“ğ±superscriptâ„ğ¶f(\mathbf{x})\in\mathbb{R}^{C}italic_f ( bold_x ) âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT and fyâ¢(ğ±)subscriptğ‘“ğ‘¦ğ±f_{y}(\mathbf{x})italic_f start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( bold_x ) denote the output logits of an instance ğ±ğ±\mathbf{x}bold_x for Cğ¶Citalic_C classes and its value for class yğ‘¦yitalic_y, respectively. â„“â¢(â‹…,â‹…)â„“â‹…â‹…\ell(\cdot,\cdot)roman_â„“ ( â‹… , â‹… ) is a loss function, and pyâ¢(ğ±)=expâ¡fyâ¢(ğ±)âˆ‘c=1Cexpâ¡fcâ¢(ğ±)subscriptğ‘ğ‘¦ğ±subscriptğ‘“ğ‘¦ğ±superscriptsubscriptğ‘1ğ¶subscriptğ‘“ğ‘ğ±p_{y}(\mathbf{x})=\frac{\exp{f_{{y}}(\mathbf{x})}}{\sum_{c=1}^{C}\exp{f_{c}(% \mathbf{x})}}italic_p start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( bold_x ) = divide start_ARG roman_exp italic_f start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( bold_x ) end_ARG start_ARG âˆ‘ start_POSTSUBSCRIPT italic_c = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT roman_exp italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( bold_x ) end_ARG is a predicted probability of class yğ‘¦yitalic_y. ğ¯ğ±subscriptğ¯ğ±\mathbf{v}_{\mathbf{x}}bold_v start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT indicates penultimate layer representation vectors of an instance ğ±ğ±\mathbf{x}bold_x, and ğ®ysubscriptğ®ğ‘¦\mathbf{u}_{y}bold_u start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT is a representative vector for class yğ‘¦yitalic_y, derived through performing eigen decomposition on the gram matrix of data representations. âŸ¨â‹…,â‹…âŸ©â‹…â‹…\langle\cdot,\cdot\rangleâŸ¨ â‹… , â‹… âŸ© denotes inner product.

Training signal |  Formula, tğ±subscriptğ‘¡ğ±t_{\mathbf{x}}italic_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT  
---|---  
Loss [[20](https://arxiv.org/html/2405.19902v1#bib.bib20)] |  â„“â¢(fâ¢(ğ±),y)â„“ğ‘“ğ±ğ‘¦\ell(f(\mathbf{x}),y)roman_â„“ ( italic_f ( bold_x ) , italic_y )  
Probability [[4](https://arxiv.org/html/2405.19902v1#bib.bib4)] |  pyâ¢(ğ±)subscriptğ‘ğ‘¦ğ±p_{y}(\mathbf{x})italic_p start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( bold_x )  
Probability difference [[45](https://arxiv.org/html/2405.19902v1#bib.bib45)] |  maxcâ¡pcâ¢(ğ±)âˆ’pyâ¢(ğ±)subscriptğ‘subscriptğ‘ğ‘ğ±subscriptğ‘ğ‘¦ğ±\max_{c}p_{c}(\mathbf{x})-p_{y}(\mathbf{x})roman_max start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( bold_x ) - italic_p start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( bold_x )  
Logit difference [[36](https://arxiv.org/html/2405.19902v1#bib.bib36)] |  fyâ¢(ğ±)âˆ’maxcâ‰ yâ¡fcâ¢(ğ±)subscriptğ‘“ğ‘¦ğ±subscriptğ‘ğ‘¦subscriptğ‘“ğ‘ğ±f_{y}(\mathbf{x})-\max_{c\neq y}f_{c}(\mathbf{x})italic_f start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( bold_x ) - roman_max start_POSTSUBSCRIPT italic_c â‰  italic_y end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( bold_x )  
Alignment of pre-logits [[22](https://arxiv.org/html/2405.19902v1#bib.bib22)] |  âŸ¨ğ®y,ğ¯ğ±âŸ©2superscriptsubscriptğ®ğ‘¦subscriptğ¯ğ±2\langle\mathbf{u}_{y},\;\mathbf{v}_{\mathbf{x}}\rangle^{2}âŸ¨ bold_u start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT , bold_v start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT âŸ© start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT  
  
Table 6: Various types of training signals. Figure 4:  Dataset construction for supervised learning.

Supervised experimental setting.  As illustrated in Figure [4](https://arxiv.org/html/2405.19902v1#A2.F4 "Figure 4 â€£ B.1 Preliminaries â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"), we generate training dynamics by employing a classifier that predicts the class probabilities for each input instance across the set of classes. Subsequently, we construct a new dataset comprising these extracted training dynamics and the corresponding ground-truth labels that are assumed to exist. This new dataset is then utilized to train a 1D convolutional neural network (1D-CNN) classifier (henceforth referred to as a binary classifier) that distinguishes between correctly and incorrectly labeled instances based on the patterns in their training dynamics. We train the binary classifier (whose encoder is the same as our dynamics encoder) for 20 epochs using the Adadelta [[61](https://arxiv.org/html/2405.19902v1#bib.bib61)] optimizer with an initial learning rate of 1 and a StepLR scheduler that reduces it by 1% for every epoch. The batch size is set to 128. During training, we monitor the modelâ€™s performance on a validation set and report the F1 score for detecting incorrectly labeled instances on the test set, corresponding to the point where the validation F1 score achieves its maximum value.

###  B.2 Temporal patterns in training dynamics

To assess the effectiveness of capturing temporal patterns within training dynamics compared to summarizing them into a single scalar value [[36](https://arxiv.org/html/2405.19902v1#bib.bib36), [4](https://arxiv.org/html/2405.19902v1#bib.bib4)], we conduct experiments using them as input to the binary classifier in the supervised setting. For the training dynamics, we use

| ğ­ğ±=[tğ±(1),..,tğ±(E)],\mathbf{t}_{\mathbf{x}}=[t^{(1)}_{\mathbf{x}},..,t^{(E)}_{\mathbf{x}}],bold_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = [ italic_t start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT , . . , italic_t start_POSTSUPERSCRIPT ( italic_E ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT ] , |  | (10)  
---|---|---|---  
  
where tğ±(e)superscriptsubscriptğ‘¡ğ±ğ‘’t_{\mathbf{x}}^{(e)}italic_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_e ) end_POSTSUPERSCRIPT is a training signal at epoch eğ‘’eitalic_e for an instance ğ±ğ±\mathbf{x}bold_x, and Eğ¸Eitalic_E is the maximum number of training epochs. For the summarized one, we use a statistical method [[36](https://arxiv.org/html/2405.19902v1#bib.bib36), [4](https://arxiv.org/html/2405.19902v1#bib.bib4)] that average the series of temporal signals into a single scalar value sğ±subscriptğ‘ ğ±s_{\mathbf{x}}italic_s start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT to encapsulate the essential features.

| sğ±=1Eâ¢âˆ‘e=1Etğ±(e),subscriptğ‘ ğ±1ğ¸superscriptsubscriptğ‘’1ğ¸superscriptsubscriptğ‘¡ğ±ğ‘’s_{\mathbf{x}}=\frac{1}{E}\sum_{e=1}^{E}t_{\mathbf{x}}^{(e)},italic_s start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_E end_ARG âˆ‘ start_POSTSUBSCRIPT italic_e = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_e ) end_POSTSUPERSCRIPT , |  | (11)  
---|---|---|---  
  
To evaluate the relative efficacy of these approaches, we use two distinct types of training signals: probability and logit difference in Table [6](https://arxiv.org/html/2405.19902v1#A2.T6 "Table 6 â€£ B.1 Preliminaries â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"). For the binary classifier of the summarized one, we adopt a multi-layer perceptron (MLP) of two hidden layers. To ensure the modelâ€™s sufficient capacity to learn patterns in the data, we increase the model parameters until performance does not improve further.

Figure 5:  Comparison of detection F1 score (%) achieved by the binary classifiers trained using the training dynamics (comb-pattern bar and star marker in legend) versus those trained with the summarized one for various noise types on CIFAR-100. Prob. and Logit diff. indicate the types of training signals in Table [6](https://arxiv.org/html/2405.19902v1#A2.T6 "Table 6 â€£ B.1 Preliminaries â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"). Noise rates of Sym., Asym., and Instance are 0.6, 0.4, and 0.3, respectively. The human-induced noise has noise rates of 0.4. CLIP w/ MLP (Left) and Resnet34 (Right) are used for training dynamics generation. 

Figure [5](https://arxiv.org/html/2405.19902v1#A2.F5 "Figure 5 â€£ B.2 Temporal patterns in training dynamics â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") shows that the models trained with the training dynamics consistently outperform those with the summarized training dynamics. The results demonstrate that temporal patterns within training dynamics help distinguish between correctly and incorrectly labeled instances.

###  B.3 Comparison of various training signals

We compare the detection F1 score of the binary classifier trained with the training dynamics derived from various training signals in the supervised setting.

Figure 6:  Comparison of detection F1 score (%) of the raw training dynamics from various training signals on CIFAR-100. Noise rates of Sym., Asym., and Instance are 0.6, 0.4, and 0.3, respectively. The human-induced noise type has noise rates of 0.4. The Avg. indicates an averaged F1 score (%) over all noise types. CLIP w/ MLP (Upper) and Resnet34 (Lower) are used for training dynamics generation. 

Figure [6](https://arxiv.org/html/2405.19902v1#A2.F6 "Figure 6 â€£ B.3 Comparison of various training signals â€£ Appendix B Analyses of Training Dynamics â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection") shows that, on average, more processed training signals, such as probability differences and alignment of pre-logits, exhibit superior performance compared to simpler ones. In this study, we select logit difference as the base proxy measure due to its consistent performance across various experimental settings. Moreover, we observe that detection performance for different types of noises is highly correlated with model architecture. We leave the study of the influence of model architectures in future work.

##  Appendix C Proof of the Lower Bound of Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT

######  Proposition 2 (Lower bound of Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT)

Let Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT denote the noise rate of the corrupted dataset. Given the diagonally dominant condition, i,e., Î·<1âˆ’1Cğœ‚11ğ¶\eta<1-\frac{1}{C}italic_Î· < 1 - divide start_ARG 1 end_ARG start_ARG italic_C end_ARG, for any Î³âˆˆ(0,1]ğ›¾01\gamma\in{\left(0,1\right]}italic_Î³ âˆˆ ( 0 , 1 ], Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT has a lower bound of 1âˆ’1C11ğ¶1-\frac{1}{C}1 - divide start_ARG 1 end_ARG start_ARG italic_C end_ARG.

Proof. The proportion of the correctly labeled instances in the corrupted dataset can be derived by multiplying the noise rate Î·ğœ‚\etaitalic_Î· of the original dataset by the probability that a noisy label is subsequently restored to its clean label due to the corrupting process, i.e., Î·â¢(1Câˆ’1)ğœ‚1ğ¶1\eta(\frac{1}{C-1})italic_Î· ( divide start_ARG 1 end_ARG start_ARG italic_C - 1 end_ARG ). This derivation holds because the corruption process randomly flips class labels to one of the other classes uniformly. Consequently, the noise rate Î·Î³subscriptğœ‚ğ›¾\eta_{\gamma}italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT of the corrupted dataset is calculated as

| Î·Î³=1âˆ’Î·â¢(1Câˆ’1).subscriptğœ‚ğ›¾1ğœ‚1ğ¶1\eta_{\gamma}=1-\eta\left(\frac{1}{C-1}\right).italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT = 1 - italic_Î· ( divide start_ARG 1 end_ARG start_ARG italic_C - 1 end_ARG ) . |  | (12)  
---|---|---|---  
  
Then, by the diagonally dominant condition, i.e., Î·<1âˆ’1Cğœ‚11ğ¶\eta<1-\frac{1}{C}italic_Î· < 1 - divide start_ARG 1 end_ARG start_ARG italic_C end_ARG, Eq. ([12](https://arxiv.org/html/2405.19902v1#A3.E12 "Equation 12 â€£ Appendix C Proof of the Lower Bound of ğœ‚_ğ›¾ â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection")) implies

| 1âˆ’1C<Î·Î³11ğ¶subscriptğœ‚ğ›¾1-\frac{1}{C}<\eta_{\gamma}1 - divide start_ARG 1 end_ARG start_ARG italic_C end_ARG < italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT |  | (13)  
---|---|---|---  
  
With this, we can derive that the corrupted dataset has a higher noise rate than the original dataset, i.e., Î·<Î·Î³ğœ‚subscriptğœ‚ğ›¾\eta<\eta_{\gamma}italic_Î· < italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT. Besides, we present the formulation of the overall noise rate of the original and corrupted datasets as

| Î·oâ¢vâ¢eâ¢r=Î·+Î³â‹…Î·Î³1+Î³.subscriptğœ‚ğ‘œğ‘£ğ‘’ğ‘Ÿğœ‚â‹…ğ›¾subscriptğœ‚ğ›¾1ğ›¾\eta_{over}=\frac{\eta+\gamma\cdot\eta_{\gamma}}{1+\gamma}.italic_Î· start_POSTSUBSCRIPT italic_o italic_v italic_e italic_r end_POSTSUBSCRIPT = divide start_ARG italic_Î· + italic_Î³ â‹… italic_Î· start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT end_ARG start_ARG 1 + italic_Î³ end_ARG . |  | (14)  
---|---|---|---  
  
##  Appendix D Compatibility analysis with robust learning on Clothing 1M dataset

We also investigate the compatibility of DynaCor with various loss functions (GCE [[64](https://arxiv.org/html/2405.19902v1#bib.bib64)], and SCE [[50](https://arxiv.org/html/2405.19902v1#bib.bib50)]) and regularization technique (ELR [[31](https://arxiv.org/html/2405.19902v1#bib.bib31)]), specifically designed for noise robust learning. To this end, we measure the test accuracy of such noise robust classifiers trained using the original Clothing1M dataset and the cleansed dataset (i.e., the one with only correctly labeled instances identified by DynaCor), respectively.

Loss type | GCE [[64](https://arxiv.org/html/2405.19902v1#bib.bib64)] | SCE [[50](https://arxiv.org/html/2405.19902v1#bib.bib50)] | ELR [[31](https://arxiv.org/html/2405.19902v1#bib.bib31)]  
---|---|---|---  
Original | 71.82 | 71.75 | 72.57  
Cleansed | 72.23 | 72.37 | 73.06  
  
Table 7: Classification accuracy (%) on Clothing1M, trained with noise robust loss functions (GCE, SCE) and regularization technique (ELR) by using the original and cleansed sets, respectively.

In Table [7](https://arxiv.org/html/2405.19902v1#A4.T7 "Table 7 â€£ Appendix D Compatibility analysis with robust learning on Clothing 1M dataset â€£ Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection"), we can observe consistent improvement in classification performance by cleansing the original dataset based on the detection results from DynaCor, even in case the classifier is trained with a noise-robust loss function or regularization technique.

Generated on Thu May 30 09:56:26 2024 by [LaTeXML](http://dlmf.nist.gov/LaTeXML/)
