# Topic Brief â€” LLM Explainability

## Target

**ACL 2026 Theme Track: Explainability of NLP Models**

## Theme Track Questions (from CFP)

1. How do explainability methods need to be adapted for different model architectures?
2. How can we rigorously evaluate the quality of an explanation?
3. Can explanations detect biased predictions?
4. Can we use explanations to find/fix problems in training data?
5. Can we identify mechanisms that control high-level behaviors?

## Initial Direction

*(To be refined after reviewing prior work)*

---

## Prior Work Input

*(Paste relevant prior work below)*



